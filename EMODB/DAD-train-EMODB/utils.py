import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import os
import json
import logging
from collections import defaultdict, deque
from scipy.stats import mode
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report
import config_emodb as cfg

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

class Emotion2VecUtils:
    """
    Emotion2Vecç›¸å…³çš„å·¥å…·ç±»
    """
    
    @staticmethod
    def load_emotion2vec_features(data_path):
        """
        åŠ è½½emotion2vecé¢„å¤„ç†åçš„ç‰¹å¾
        
        Args:
            data_path: æ•°æ®è·¯å¾„å‰ç¼€ï¼ˆä¸åŒ…å«æ‰©å±•åï¼‰
            
        Returns:
            dict: åŒ…å«ç‰¹å¾æ•°æ®çš„å­—å…¸
        """
        try:
            # åŠ è½½ç‰¹å¾æ•°æ®
            npy_data = np.load(data_path + ".npy")
            
            # åŠ è½½é•¿åº¦ä¿¡æ¯
            with open(data_path + ".lengths", "r") as f:
                lengths = [int(line.strip()) for line in f.readlines()]
            
            # å°è¯•åŠ è½½æ ‡ç­¾
            labels = None
            label_file = data_path + ".emo"
            if os.path.exists(label_file):
                with open(label_file, "r") as f:
                    labels = [line.strip().split()[1] for line in f.readlines()]
            
            logger.info(f"âœ… æˆåŠŸåŠ è½½emotion2vecç‰¹å¾: {data_path}")
            logger.info(f"   ç‰¹å¾å½¢çŠ¶: {npy_data.shape}")
            logger.info(f"   æ ·æœ¬æ•°é‡: {len(lengths)}")
            logger.info(f"   æ ‡ç­¾æ•°é‡: {len(labels) if labels else 0}")
            
            return {
                'features': npy_data,
                'lengths': lengths,
                'labels': labels,
                'feature_dim': npy_data.shape[1]
            }
            
        except Exception as e:
            logger.error(f"âŒ åŠ è½½emotion2vecç‰¹å¾å¤±è´¥: {data_path}, é”™è¯¯: {e}")
            raise
    
    @staticmethod
    def compute_padding_mask(batch_features, max_length=None):
        """
        è®¡ç®—æ‰¹æ¬¡çš„padding mask
        
        Args:
            batch_features: ç‰¹å¾åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º (seq_len, feature_dim)
            max_length: æœ€å¤§é•¿åº¦ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨æ‰¹æ¬¡ä¸­çš„æœ€å¤§é•¿åº¦
            
        Returns:
            tuple: (padded_features, padding_mask)
        """
        if max_length is None:
            max_length = max(feat.shape[0] for feat in batch_features)
        
        batch_size = len(batch_features)
        feature_dim = batch_features[0].shape[1]
        
        # åˆ›å»ºå¡«å……åçš„ç‰¹å¾å¼ é‡
        padded_features = torch.zeros(batch_size, max_length, feature_dim)
        padding_mask = torch.ones(batch_size, max_length, dtype=torch.bool)
        
        for i, feat in enumerate(batch_features):
            seq_len = feat.shape[0]
            padded_features[i, :seq_len] = feat
            padding_mask[i, :seq_len] = False
        
        return padded_features, padding_mask
    
    @staticmethod
    def validate_emotion2vec_data(data_path):
        """
        éªŒè¯emotion2vecæ•°æ®çš„å®Œæ•´æ€§
        
        Args:
            data_path: æ•°æ®è·¯å¾„å‰ç¼€
            
        Returns:
            bool: æ•°æ®æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            required_files = [
                data_path + ".npy",
                data_path + ".lengths"
            ]
            
            for file_path in required_files:
                if not os.path.exists(file_path):
                    logger.error(f"âŒ ç¼ºå°‘å¿…éœ€æ–‡ä»¶: {file_path}")
                    return False
            
            # éªŒè¯æ•°æ®ä¸€è‡´æ€§
            npy_data = np.load(data_path + ".npy")
            with open(data_path + ".lengths", "r") as f:
                lengths = [int(line.strip()) for line in f.readlines()]
            
            total_length = sum(lengths)
            if total_length != npy_data.shape[0]:
                logger.error(f"âŒ é•¿åº¦ä¸åŒ¹é…: æ€»é•¿åº¦={total_length}, ç‰¹å¾è¡Œæ•°={npy_data.shape[0]}")
                return False
            
            logger.info(f"âœ… emotion2vecæ•°æ®éªŒè¯é€šè¿‡: {data_path}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®éªŒè¯å¤±è´¥: {e}")
            return False

class ModelUtils:
    """
    æ¨¡å‹ç›¸å…³çš„å·¥å…·å‡½æ•°
    """
    
    @staticmethod
    def count_parameters(model):
        """
        ç»Ÿè®¡æ¨¡å‹å‚æ•°æ•°é‡
        
        Args:
            model: PyTorchæ¨¡å‹
            
        Returns:
            dict: å‚æ•°ç»Ÿè®¡ä¿¡æ¯
        """
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        frozen_params = total_params - trainable_params
        
        return {
            'total_params': total_params,
            'trainable_params': trainable_params,
            'frozen_params': frozen_params,
            'trainable_ratio': trainable_params / total_params if total_params > 0 else 0
        }
    
    @staticmethod
    def print_model_info(model, model_name="Model"):
        """
        æ‰“å°æ¨¡å‹ä¿¡æ¯
        
        Args:
            model: PyTorchæ¨¡å‹
            model_name: æ¨¡å‹åç§°
        """
        param_info = ModelUtils.count_parameters(model)
        
        logger.info(f"ğŸ“Š {model_name} å‚æ•°ç»Ÿè®¡:")
        logger.info(f"   æ€»å‚æ•°: {param_info['total_params']:,}")
        logger.info(f"   å¯è®­ç»ƒå‚æ•°: {param_info['trainable_params']:,}")
        logger.info(f"   å†»ç»“å‚æ•°: {param_info['frozen_params']:,}")
        logger.info(f"   å¯è®­ç»ƒæ¯”ä¾‹: {param_info['trainable_ratio']:.2%}")
    
    @staticmethod
    def save_model_checkpoint(model, optimizer, epoch, metrics, save_path):
        """
        ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹
        
        Args:
            model: PyTorchæ¨¡å‹
            optimizer: ä¼˜åŒ–å™¨
            epoch: å½“å‰epoch
            metrics: è¯„ä¼°æŒ‡æ ‡å­—å…¸
            save_path: ä¿å­˜è·¯å¾„
        """
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'metrics': metrics,
            'model_info': ModelUtils.count_parameters(model)
        }
        
        torch.save(checkpoint, save_path)
        logger.info(f"ğŸ’¾ æ¨¡å‹æ£€æŸ¥ç‚¹å·²ä¿å­˜: {save_path}")
    
    @staticmethod
    def load_model_checkpoint(model, optimizer, checkpoint_path):
        """
        åŠ è½½æ¨¡å‹æ£€æŸ¥ç‚¹
        
        Args:
            model: PyTorchæ¨¡å‹
            optimizer: ä¼˜åŒ–å™¨
            checkpoint_path: æ£€æŸ¥ç‚¹è·¯å¾„
            
        Returns:
            dict: æ£€æŸ¥ç‚¹ä¿¡æ¯
        """
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        
        model.load_state_dict(checkpoint['model_state_dict'])
        if optimizer is not None:
            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        
        logger.info(f"ğŸ“¥ æ¨¡å‹æ£€æŸ¥ç‚¹å·²åŠ è½½: {checkpoint_path}")
        logger.info(f"   Epoch: {checkpoint['epoch']}")
        logger.info(f"   æŒ‡æ ‡: {checkpoint.get('metrics', {})}")
        
        return checkpoint

class MetricsCalculator:
    """
    è¯„ä¼°æŒ‡æ ‡è®¡ç®—å™¨
    """
    
    @staticmethod
    def compute_classification_metrics(y_true, y_pred, class_names=None, average='weighted'):
        """
        è®¡ç®—åˆ†ç±»ä»»åŠ¡çš„å„ç§æŒ‡æ ‡
        
        Args:
            y_true: çœŸå®æ ‡ç­¾
            y_pred: é¢„æµ‹æ ‡ç­¾
            class_names: ç±»åˆ«åç§°åˆ—è¡¨
            average: å¹³å‡æ–¹å¼
            
        Returns:
            dict: åŒ…å«å„ç§æŒ‡æ ‡çš„å­—å…¸
        """
        metrics = {
            'accuracy': accuracy_score(y_true, y_pred),
            'f1_score': f1_score(y_true, y_pred, average=average),
            'precision': precision_score(y_true, y_pred, average=average, zero_division=0),
            'recall': recall_score(y_true, y_pred, average=average, zero_division=0)
        }
        
        # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„æŒ‡æ ‡
        if class_names is not None:
            per_class_f1 = f1_score(y_true, y_pred, average=None, zero_division=0)
            for i, class_name in enumerate(class_names):
                if i < len(per_class_f1):
                    metrics[f'f1_{class_name}'] = per_class_f1[i]
        
        return metrics
    
    @staticmethod
    def compute_confidence_stats(logits, threshold=0.8):
        """
        è®¡ç®—ç½®ä¿¡åº¦ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            logits: æ¨¡å‹è¾“å‡ºçš„logits
            threshold: ç½®ä¿¡åº¦é˜ˆå€¼
            
        Returns:
            dict: ç½®ä¿¡åº¦ç»Ÿè®¡ä¿¡æ¯
        """
        probs = F.softmax(logits, dim=1)
        max_probs, pred_labels = torch.max(probs, dim=1)
        
        high_confidence_mask = max_probs >= threshold
        high_confidence_count = high_confidence_mask.sum().item()
        total_count = logits.shape[0]
        
        return {
            'high_confidence_count': high_confidence_count,
            'total_count': total_count,
            'high_confidence_ratio': high_confidence_count / total_count if total_count > 0 else 0,
            'mean_confidence': max_probs.mean().item(),
            'std_confidence': max_probs.std().item(),
            'min_confidence': max_probs.min().item(),
            'max_confidence': max_probs.max().item()
        }
    
    @staticmethod
    def print_classification_report(y_true, y_pred, class_names=None, title="Classification Report"):
        """
        æ‰“å°è¯¦ç»†çš„åˆ†ç±»æŠ¥å‘Š
        
        Args:
            y_true: çœŸå®æ ‡ç­¾
            y_pred: é¢„æµ‹æ ‡ç­¾
            class_names: ç±»åˆ«åç§°åˆ—è¡¨
            title: æŠ¥å‘Šæ ‡é¢˜
        """
        logger.info(f"\nğŸ“Š {title}")
        logger.info("=" * 60)
        
        # åŸºæœ¬æŒ‡æ ‡
        metrics = MetricsCalculator.compute_classification_metrics(y_true, y_pred, class_names)
        logger.info(f"å‡†ç¡®ç‡: {metrics['accuracy']:.4f}")
        logger.info(f"F1åˆ†æ•°: {metrics['f1_score']:.4f}")
        logger.info(f"ç²¾ç¡®ç‡: {metrics['precision']:.4f}")
        logger.info(f"å¬å›ç‡: {metrics['recall']:.4f}")
        
        # è¯¦ç»†æŠ¥å‘Š
        if class_names is not None:
            target_names = class_names
        else:
            target_names = None
            
        report = classification_report(y_true, y_pred, target_names=target_names, zero_division=0)
        logger.info(f"\nè¯¦ç»†æŠ¥å‘Š:\n{report}")

class DataAugmentation:
    """
    ç»Ÿä¸€çš„æ•°æ®å¢å¼ºæ¨¡å—ï¼šæ•™å¸ˆå¼±å¢å¼º vs å­¦ç”Ÿå¼ºå¢å¼º
    æ”¯æŒå®Œæ•´çš„å¢å¼ºç­–ç•¥ï¼šå™ªå£°æ³¨å…¥ã€ç‰¹å¾dropoutã€æ—¶åºé®ç›–
    """
    def __init__(self, weak_noise_std=None, strong_noise_std=None, dropout_rate=None, temporal_mask_ratio=None):
        self.weak_noise_std = weak_noise_std if weak_noise_std is not None else cfg.WEAK_NOISE_STD
        self.strong_noise_std = strong_noise_std if strong_noise_std is not None else cfg.STRONG_NOISE_STD
        self.dropout_rate = dropout_rate if dropout_rate is not None else cfg.DROPOUT_RATE
        self.temporal_mask_ratio = temporal_mask_ratio if temporal_mask_ratio is not None else cfg.TEMPORAL_MASK_RATIO
    
    def weak_augment(self, data):
        """æ•™å¸ˆç½‘ç»œå¼±å¢å¼ºï¼šä»…æ·»åŠ å°å¹…é«˜æ–¯å™ªå£°"""
        noise = torch.randn_like(data) * self.weak_noise_std
        return data + noise
    
    def strong_augment(self, data):
        """å­¦ç”Ÿç½‘ç»œå¼ºå¢å¼ºï¼šå™ªå£°æ³¨å…¥ + ç‰¹å¾dropout + æ—¶åºé®ç›–"""
        augmented = data.clone()
        
        # 1. å™ªå£°æ³¨å…¥
        noise = torch.randn_like(augmented) * self.strong_noise_std
        augmented = augmented + noise
        
        # 2. ç‰¹å¾çº§dropout
        if self.dropout_rate > 0:
            feature_mask = torch.rand(augmented.shape[-1], device=augmented.device) > self.dropout_rate
            augmented = augmented * feature_mask.float()
        
        # 3. æ—¶åºé®ç›–ï¼ˆå¦‚æœæ˜¯åºåˆ—æ•°æ®ï¼‰
        if self.temporal_mask_ratio > 0 and len(augmented.shape) >= 2:
            augmented = self._apply_temporal_masking(augmented)
        
        return augmented
    
    def _apply_temporal_masking(self, data):
        """åº”ç”¨æ—¶åºé®ç›–"""
        if len(data.shape) == 2:  # [seq_len, feature_dim]
            seq_len = data.shape[0]
            mask_len = int(seq_len * self.temporal_mask_ratio)
            
            if mask_len > 0:
                start_idx = torch.randint(0, max(1, seq_len - mask_len + 1), (1,)).item()
                data_masked = data.clone()
                data_masked[start_idx:start_idx + mask_len] = 0
                return data_masked
                
        elif len(data.shape) == 3:  # [batch_size, seq_len, feature_dim]
            batch_size, seq_len = data.shape[0], data.shape[1]
            mask_len = int(seq_len * self.temporal_mask_ratio)
            
            if mask_len > 0:
                data_masked = data.clone()
                for i in range(batch_size):
                    start_idx = torch.randint(0, max(1, seq_len - mask_len + 1), (1,)).item()
                    data_masked[i, start_idx:start_idx + mask_len] = 0
                return data_masked
        
        return data

# ===== ä»¥ä¸‹æ˜¯æ ¹æ®æ‚¨çš„æ–°æ–¹æ³•æ·»åŠ çš„æ¨¡å— =====

class DACPManager:
    """
    åŠ¨æ€è‡ªé€‚åº”ç½®ä¿¡åº¦å‰ªæ (DACP) ç®¡ç†å™¨
    å®ç°è®ºæ–‡ 3.3 èŠ‚çš„å®Œæ•´é€»è¾‘
    """
    def __init__(self, num_classes, total_epochs, device):
        self.num_classes = num_classes
        self.total_epochs = total_epochs
        self.device = device
        
        # é˜¶æ®µäºŒï¼šç±»åˆ«è¡¨ç°è¿½è¸ª (å…¬å¼ 10)
        # æ¯ä¸ªç±»åˆ«çš„ä¼ªæ ‡ç­¾è´¨é‡åˆ†æ•° Q_c^e, åˆå§‹åŒ–ä¸º0.5
        self.class_quality_scores = torch.full((num_classes,), 0.5, device=self.device)

        # é˜¶æ®µå››ï¼šæœ€ç»ˆé˜ˆå€¼å¹³æ»‘ (å…¬å¼ 17)
        # æ¯ä¸ªç±»åˆ«çš„æœ€ç»ˆé˜ˆå€¼ Ï„_c^t, åˆå§‹åŒ–ä¸º0.5
        self.ema_thresholds = torch.full((num_classes,), 0.5, device=self.device)
        
        # æ‰¹æ¬¡ä¸­æ¯ä¸ªç±»åˆ«çš„ç¡®å®šæ€§åˆ†æ•°é›†åˆï¼Œç”¨äºè®¡ç®—åˆ†ä½æ•°
        self.batch_scores_per_class = [[] for _ in range(num_classes)]

    @staticmethod
    def calculate_certainty_scores(probs):
        """
        é˜¶æ®µä¸€ï¼šè®¡ç®—ä¿®æ­£åçš„ç¡®å®šæ€§åˆ†æ•° (å…¬å¼ 8)
        Args:
            probs: æ•™å¸ˆç½‘ç»œè¾“å‡ºçš„æ¦‚ç‡åˆ†å¸ƒ [B, C]
        Returns:
            scores: æ¯ä¸ªæ ·æœ¬çš„ç¡®å®šæ€§åˆ†æ•° [B]
            preds: æ¯ä¸ªæ ·æœ¬çš„é¢„æµ‹ç±»åˆ« [B]
        """
        max_probs, preds = torch.max(probs, dim=1)
        
        # è®¡ç®—ç†µ (å…¬å¼ 7)
        entropy = -torch.sum(probs * torch.log2(probs + 1e-8), dim=1)
        
        # å½’ä¸€åŒ–ç†µ
        normalized_entropy = entropy / np.log2(probs.size(1))
        
        # è®¡ç®—ç¡®å®šæ€§åˆ†æ•° (å…¬å¼ 8)
        certainty_scores = max_probs * (1 - normalized_entropy)
        return certainty_scores, preds

    def update_class_quality_scores_epoch(self, epoch_scores_per_class):
        """
        é˜¶æ®µäºŒï¼šæ›´æ–°æ¯ä¸ªç±»åˆ«çš„æ•´ä½“è´¨é‡åˆ†æ•° Q_c^e (å…¬å¼ 9, 10)
        åº”åœ¨æ¯ä¸ª epoch ç»“æŸåè°ƒç”¨
        """
        current_epoch_quality = torch.tensor(
            [np.mean(scores) if len(scores) > 0 else self.class_quality_scores[i].item() for i, scores in enumerate(epoch_scores_per_class)],
            device=self.device,
            dtype=torch.float32
        )
        
        # EMA æ›´æ–° (å…¬å¼ 10)
        self.class_quality_scores = (
            cfg.DACP_QUALITY_SMOOTHING_BETA * self.class_quality_scores +
            (1 - cfg.DACP_QUALITY_SMOOTHING_BETA) * current_epoch_quality
        )
        # æ¸…ç©ºç”¨äºå­˜å‚¨æ•´ä¸ªepochåˆ†æ•°çš„åˆ—è¡¨
        self.batch_scores_per_class = [[] for _ in range(self.num_classes)]

    def calculate_mask(self, teacher_probs, epoch, calibrated_anchors):
        """
        è®¡ç®—æœ€ç»ˆçš„ç½®ä¿¡åº¦æ©ç  (DACP æ ¸å¿ƒé€»è¾‘)
        Args:
            teacher_probs: æ•™å¸ˆç½‘ç»œè¾“å‡ºçš„æ¦‚ç‡ [B, C]
            epoch: å½“å‰è½®æ¬¡
            calibrated_anchors: é¢„å…ˆè®¡ç®—å¥½çš„åŠ¨æ€æ ¡å‡†é”šç‚¹ [C]
        Returns:
            mask: é«˜ç½®ä¿¡åº¦æ ·æœ¬çš„äºŒå€¼æ©ç  [B]
            certainty_scores: æ‰€æœ‰æ ·æœ¬çš„ç¡®å®šæ€§åˆ†æ•° [B]
            class_weights_wce: ç±»åˆ«æƒé‡ W_c^e [C]
        """
        # é˜¶æ®µä¸€ï¼šè®¡ç®—ç¡®å®šæ€§åˆ†æ•°
        certainty_scores, preds = self.calculate_certainty_scores(teacher_probs)
        
        # --- é˜¶æ®µä¸‰ & å›› å¼€å§‹ ---
        # 1. è®¡ç®—ç›¸å¯¹è¡¨ç°å·®è· Î”_c^e å’Œç±»åˆ«æƒé‡ W_c^e (å…¬å¼ 11, 12)
        avg_quality = self.class_quality_scores.mean()
        delta_ce = self.class_quality_scores - avg_quality
        # ä½¿ç”¨ sigmoid è®¡ç®—ç±»åˆ«æƒé‡ (å…¬å¼ 12)
        class_weights_wce = torch.sigmoid(cfg.DACP_SENSITIVITY_K * delta_ce)

        # 2. è®¡ç®—åŠ¨æ€ç­›é€‰æ ‡å‡† Î³_e (å…¬å¼ 13)
        progress = epoch / self.total_epochs
        gamma_e = cfg.DACP_QUANTILE_START + (cfg.DACP_QUANTILE_END - cfg.DACP_QUANTILE_START) * progress
        
        # 3. è®¡ç®—æ‰¹æ¬¡å†…å„ç±»åˆ«åŸºç¡€é˜ˆå€¼ Ï„_c^t (å…¬å¼ 14)
        batch_thresholds_tct = torch.zeros(self.num_classes, device=self.device)
        for c in range(self.num_classes):
            class_scores = certainty_scores[preds == c]
            if len(class_scores) > 0:
                # Quantile(U_c^t, Î³_e)
                batch_thresholds_tct[c] = torch.quantile(class_scores, gamma_e)
            else:
                # å¦‚æœæ‰¹æ¬¡å†…æ²¡æœ‰è¯¥ç±»åˆ«ï¼Œä½¿ç”¨EMAå¹³æ»‘åçš„å†å²é˜ˆå€¼
                batch_thresholds_tct[c] = self.ema_thresholds[c]

        # 4. è®¡ç®—åŠ¨æ€è°ƒæ•´é¡¹å’Œèåˆé”šç‚¹ (å…¬å¼ 15, 16)
        dynamic_adjustment = cfg.DACP_CALIBRATION_STRENGTH_LAMBDA * (class_weights_wce - 0.5)
        dynamic_thresholds = batch_thresholds_tct + dynamic_adjustment
        
        # èåˆé”šç‚¹ï¼Œç¡®ä¿ä¸ä½äºåº•çº¿ (å…¬å¼ 16)
        floored_thresholds = torch.max(dynamic_thresholds, calibrated_anchors.to(self.device))

        # 5. EMAå¹³æ»‘æœ€ç»ˆé˜ˆå€¼ (å…¬å¼ 17)
        self.ema_thresholds = (
            cfg.DACP_THRESHOLD_SMOOTHING_ALPHA * self.ema_thresholds +
            (1 - cfg.DACP_THRESHOLD_SMOOTHING_ALPHA) * floored_thresholds
        )

        # 6. ç”Ÿæˆæœ€ç»ˆæ©ç  (å…¬å¼ 18)
        final_thresholds_per_sample = self.ema_thresholds[preds]
        mask = certainty_scores >= final_thresholds_per_sample
        
        # ä¸ºä¸‹ä¸€ä¸ªepochçš„è´¨é‡æ›´æ–°æ”¶é›†åˆ†æ•°
        for c in range(self.num_classes):
            self.batch_scores_per_class[c].extend(certainty_scores[preds == c].detach().cpu().numpy())

        return mask, certainty_scores, class_weights_wce


class ECDALoss(nn.Module):
    """
    åŸºäºèƒ½é‡æœ€å°åŒ–çš„ç±»åˆ«æ„ŸçŸ¥åˆ†å¸ƒå¯¹é½ (ECDA) æŸå¤±
    å®ç°è®ºæ–‡ 3.4 èŠ‚çš„å®Œæ•´é€»è¾‘
    """
    def __init__(self, kernel_type='rbf', kernel_mul=2.0, kernel_num=5):
        super().__init__()
        self.kernel_type = kernel_type
        self.kernel_mul = kernel_mul
        self.kernel_num = kernel_num

    def _gaussian_kernel(self, source, target, sample_weights_s, sample_weights_t):
        """
        ä¿®æ”¹ç‰ˆé«˜æ–¯æ ¸ï¼Œç”¨äºè®¡ç®—å¸¦æ ·æœ¬æƒé‡çš„ MMD
        Args:
            source: æºåŸŸç‰¹å¾ [N_s, D]
            target: ç›®æ ‡åŸŸç‰¹å¾ [N_t, D]
            sample_weights_s: æºåŸŸæ ·æœ¬æƒé‡ [N_s]
            sample_weights_t: ç›®æ ‡åŸŸæ ·æœ¬æƒé‡ [N_t]
        Returns:
            Term_ss, Term_tt, Term_st
        """
        n_s, n_t = source.size(0), target.size(0)
        total = torch.cat([source, target], dim=0)
        total0 = total.unsqueeze(0).expand(total.size(0), total.size(0), total.size(1))
        total1 = total.unsqueeze(1).expand(total.size(0), total.size(0), total.size(1))
        
        L2_dist = ((total0 - total1)**2).sum(2)
        
        # MMD original paper logic to calculate bandwidth
        bandwidth = torch.sum(L2_dist.data) / ( (n_s + n_t)**2 - (n_s + n_t) ) if (n_s + n_t) > 1 else torch.tensor(1.0)
        bandwidth /= self.kernel_mul ** (self.kernel_num // 2)
        bandwidth_list = [bandwidth * (self.kernel_mul**i) for i in range(self.kernel_num)]
        kernel_val = [torch.exp(-L2_dist / (bw + 1e-8)) for bw in bandwidth_list]
        kernel_matrix = sum(kernel_val)

        # æå–å„ä¸ªå—
        K_ss = kernel_matrix[:n_s, :n_s]
        K_tt = kernel_matrix[n_s:, n_s:]
        K_st = kernel_matrix[:n_s, n_s:]
        
        # åº”ç”¨æ³¨æ„åŠ›æƒé‡ (å…¬å¼ 21, 22, 23)
        weights_s_matrix = torch.outer(sample_weights_s, sample_weights_s)
        weights_t_matrix = torch.outer(sample_weights_t, sample_weights_t)
        weights_st_matrix = torch.outer(sample_weights_s, sample_weights_t)

        # Term_clean (å…¬å¼ 21)
        term_ss = (K_ss * weights_s_matrix).sum() / (weights_s_matrix.sum() + 1e-8)
        # Term_noisy (å…¬å¼ 22)
        term_tt = (K_tt * weights_t_matrix).sum() / (weights_t_matrix.sum() + 1e-8)
        # Term_cross (å…¬å¼ 23)
        term_st = (K_st * weights_st_matrix).sum() / (weights_st_matrix.sum() + 1e-8)

        return term_ss, term_tt, term_st

    def forward(self, clean_feats, noisy_feats, clean_labels, noisy_labels, noisy_mask, noisy_scores, class_weights_wce):
        total_loss = torch.tensor(0.0, device=clean_feats.device)
        num_classes = class_weights_wce.size(0)

        # æ£€æŸ¥noisy_maskç±»å‹ï¼Œå¦‚æœä¸æ˜¯å¸ƒå°”ç±»å‹åˆ™è½¬æ¢
        if noisy_mask.dtype != torch.bool:
            # å½“æ²¡æœ‰ä½¿ç”¨DACPæ—¶ï¼Œnoisy_maskå®é™…ä¸Šæ˜¯ç½®ä¿¡åº¦åˆ†æ•°
            # ä½¿ç”¨å›ºå®šé˜ˆå€¼å°†å…¶è½¬æ¢ä¸ºå¸ƒå°”æ©ç 
            noisy_mask = noisy_mask > cfg.FIXED_CONFIDENCE_THRESHOLD

        # è®¡ç®—æ‰€æœ‰å«å™ªç‰¹å¾ç°‡çš„è´¨å¿ƒ (ç”¨äºç±»é—´æ–¥åŠ›)
        noisy_centroids = []
        valid_centroid_classes = []
        for c in range(num_classes):
            class_noisy_feats = noisy_feats[(noisy_labels == c) & noisy_mask]
            if len(class_noisy_feats) > 0:
                noisy_centroids.append(class_noisy_feats.mean(dim=0))
                valid_centroid_classes.append(c)
        
        # è®¡ç®—ç±»é—´æ–¥åŠ›æŸå¤± (å…¬å¼ 27)
        repulsion_loss = torch.tensor(0.0, device=clean_feats.device)
        if len(noisy_centroids) > 1:
            centroids_tensor = torch.stack(noisy_centroids)
            dist_matrix = torch.pdist(centroids_tensor, p=2)
            repulsion_loss = -dist_matrix.mean()
        
        # è®¡ç®—ç±»åˆ«çº§æ³¨æ„åŠ›æƒé‡ (å…¬å¼ 24)
        avg_class_weight = class_weights_wce.mean()
        class_attention_weights = torch.exp(cfg.ECDA_CLASS_ATTENTION_LAMBDA * (avg_class_weight - class_weights_wce))
        
        for c in range(num_classes):
            # 1. æå–æ¯ä¸ªç±»åˆ«çš„ç‰¹å¾ (å…¬å¼ 19)
            class_clean_feats = clean_feats[clean_labels == c]
            
            noisy_class_mask = (noisy_labels == c) & noisy_mask
            class_noisy_feats = noisy_feats[noisy_class_mask]
            
            # è®¡ç®—å¯è¡Œæ€§é—¨æ§ (è®ºæ–‡ 3.4 é˜¶æ®µäºŒ)
            if len(class_clean_feats) < 2 or len(class_noisy_feats) < 2:
                continue

            # 2. æ³¨æ„åŠ›åŠ æƒMMD (å…¬å¼ 20)
            clean_weights = torch.ones(len(class_clean_feats), device=clean_feats.device)
            noisy_weights = noisy_scores[noisy_class_mask]  # æ ·æœ¬çº§æ³¨æ„åŠ›
            
            term_ss, term_tt, term_st = self._gaussian_kernel(class_clean_feats, class_noisy_feats, clean_weights, noisy_weights)
            mmd_attn_loss = term_ss + term_tt - 2 * term_st

            # 3. åˆ†å¸ƒç´§å‡‘æ€§æ­£åˆ™åŒ– (å…¬å¼ 25)
            noisy_centroid = class_noisy_feats.mean(dim=0)
            compactness_loss = torch.mean(torch.sum((class_noisy_feats - noisy_centroid)**2, dim=1))
            
            # 4. æœ€ç»ˆå¯¹é½æŸå¤± (å…¬å¼ 28)
            # L_repulsion æ˜¯å…¨å±€çš„ï¼Œä½†æˆ‘ä»¬åœ¨æ¯ä¸ªç±»åˆ«å¾ªç¯ä¸­éƒ½åŠ ä¸Šå®ƒ, æœ€ç»ˆä¼šè¢«ç±»åˆ«æƒé‡ç¼©æ”¾
            ecda_loss_c = (
                mmd_attn_loss + 
                cfg.ECDA_COMPACTNESS_WEIGHT_GAMMA * compactness_loss +
                cfg.ECDA_REPULSION_WEIGHT_DELTA * repulsion_loss
            )
            
            # 5. æ€»æŸå¤±åŠ æƒæ±‚å’Œ (å…¬å¼ 29)
            total_loss += class_attention_weights[c] * ecda_loss_c

        return total_loss
