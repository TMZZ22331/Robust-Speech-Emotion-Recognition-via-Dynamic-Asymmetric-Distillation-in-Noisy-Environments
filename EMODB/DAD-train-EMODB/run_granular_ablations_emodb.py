import os
import json
import importlib
import glob
import pandas as pd
import re
import logging

# é…ç½®æ—¥å¿—è®°å½•
logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

def run_single_experiment(experiment_name, config_overrides, fold):
    """
    è¿è¡Œå•æ¬¡EMODBå®éªŒã€‚
    :param experiment_name: å®éªŒåç§°ï¼Œç”¨äºåˆ›å»ºç‹¬ç«‹çš„ç»“æœç›®å½•ã€‚
    :param config_overrides: éœ€è¦è¦†ç›–çš„é…ç½®é¡¹ã€‚
    :param fold: äº¤å‰éªŒè¯çš„æŠ˜æ•°ã€‚
    :return: ä¸€ä¸ªåŒ…å« 'WA' å’Œ 'W-F1' çš„å­—å…¸ã€‚
    """
    logger.info(f"--- ğŸš€ å¼€å§‹EMODBæ¶ˆèå®éªŒ: {experiment_name} (Fold {fold+1}) ---")
    
    # --- åŠ¨æ€åŠ è½½å’Œä¿®æ”¹é…ç½® ---
    import config_emodb as config
    importlib.reload(config)
    
    for key, value in config_overrides.items():
        setattr(config, key, value)
        logger.info(f"  ğŸ”§ è®¾ç½®å‚æ•°: {key} = {value}")
    
    # --- âš ï¸ å…³é”®ä¿®å¤2ï¼šæ›´æ–°ä¾èµ–è·¯å¾„ ---
    if 'NOISY_DATA_DIR' in config_overrides:
        import os
        config.NOISY_FEAT_PATH = os.path.join(config.NOISY_DATA_DIR, "train")
        logger.info(f"  ğŸ“ å™ªå£°ç‰¹å¾è·¯å¾„å·²æ›´æ–°: {config.NOISY_FEAT_PATH}")
    
    # --- âš ï¸ å…³é”®ä¿®å¤1ï¼šè®¾ç½®éšæœºç§å­å’Œç¯å¢ƒ ---
    config.setup_environment()
    logger.info(f"  ğŸ² éšæœºç§å­å·²è®¾ç½®: {config.RANDOM_SEED}")

    # --- è¿è¡Œè®­ç»ƒ ---
    import train_emodb as train
    importlib.reload(train)
    
    trainer = train.FixedEMODBCrossDomainTrainer(fold=fold, experiment_name=experiment_name)
    train_results = trainer.train()
    
    # --- æå–ç»“æœ ---
    results_dir = train_results['results_dir']
    report_path_pattern = os.path.join(results_dir, "reports", "BEST_detailed_results_epoch_*.json")
    
    list_of_files = glob.glob(report_path_pattern)
    if not list_of_files:
        logger.error(f"âŒ åœ¨ {results_dir} ä¸­æœªæ‰¾åˆ° 'BEST' ç»“æœæŠ¥å‘Šã€‚")
        return {'WA (%)': 'Error', 'W-F1 (%)': 'Error'}
        
    latest_file = max(list_of_files, key=os.path.getctime)
    
    logger.info(f"  ğŸ“Š è¯»å–æŠ¥å‘Š: {os.path.basename(latest_file)}")
    
    with open(latest_file, 'r', encoding='utf-8') as f:
        report_data = json.load(f)
        
    noisy_summary = report_data['summary']['noisy']
    wa = float(noisy_summary['w_acc'].replace('%', ''))
    w_f1 = float(noisy_summary['w_f1'].replace('%', ''))
    
    logger.info(f"--- âœ… å®éªŒç»“æŸ: {experiment_name} (Fold {fold+1}) | WA: {wa:.2f}%, W-F1: {w_f1:.2f}% ---")
    
    return {'WA (%)': wa, 'W-F1 (%)': w_f1}

def run_experiment_on_multiple_noises(experiment_name, base_settings, noise_types, fold):
    """
    åœ¨å¤šç§å™ªå£°ç±»å‹ä¸Šè¿è¡Œå•ä¸ªå®éªŒï¼Œå¹¶è®¡ç®—å¹³å‡æ€§èƒ½
    :param experiment_name: å®éªŒåŸºç¡€åç§°
    :param base_settings: åŸºç¡€é…ç½®è®¾ç½®
    :param noise_types: å™ªå£°ç±»å‹å­—å…¸ {'noise_name': 'path'}
    :param fold: äº¤å‰éªŒè¯æŠ˜æ•°
    :return: å¹³å‡ç»“æœå­—å…¸
    """
    logger.info(f"\n{'='*70}")
    logger.info(f"ğŸ§ª å¼€å§‹å¤šå™ªå£°å®éªŒ: {experiment_name}")
    logger.info(f"    ğŸ“Š å°†åœ¨ {len(noise_types)} ç§å™ªå£°ç±»å‹ä¸Šæµ‹è¯•: {list(noise_types.keys())}")
    logger.info(f"{'='*70}")
    
    noise_results = {}
    
    for noise_name, noise_path in noise_types.items():
        logger.info(f"\n--- ğŸ”Š æµ‹è¯•å™ªå£°ç±»å‹: {noise_name} ---")
        
        # ä¸ºæ¯ç§å™ªå£°ç±»å‹åˆ›å»ºå®Œæ•´çš„é…ç½®
        full_settings = base_settings.copy()
        full_settings['NOISY_DATA_DIR'] = noise_path
        
        # åˆ›å»ºå¸¦å™ªå£°ç±»å‹çš„å®éªŒåç§°
        full_experiment_name = f"{experiment_name}_{noise_name}_10db"
        
        try:
            result = run_single_experiment(full_experiment_name, full_settings, fold)
            noise_results[noise_name] = result
            logger.info(f"âœ… {noise_name} å®Œæˆ - WA: {result['WA (%)']}%, W-F1: {result['W-F1 (%)']}%")
        except Exception as e:
            logger.error(f"âŒ {noise_name} å¤±è´¥: {str(e)}")
            noise_results[noise_name] = {'WA (%)': 'Error', 'W-F1 (%)': 'Error'}
    
    # è®¡ç®—æœ‰æ•ˆç»“æœçš„å¹³å‡å€¼
    valid_wa_results = []
    valid_f1_results = []
    
    for noise_name, result in noise_results.items():
        if isinstance(result['WA (%)'], (int, float)):
            valid_wa_results.append(result['WA (%)'])
        if isinstance(result['W-F1 (%)'], (int, float)):
            valid_f1_results.append(result['W-F1 (%)'])
    
    if valid_wa_results and valid_f1_results:
        avg_wa = sum(valid_wa_results) / len(valid_wa_results)
        avg_f1 = sum(valid_f1_results) / len(valid_f1_results)
        
        logger.info(f"\nğŸ“ˆ {experiment_name} å¹³å‡æ€§èƒ½:")
        logger.info(f"    ğŸ¯ å¹³å‡WA: {avg_wa:.2f}% (åŸºäº {len(valid_wa_results)}/{len(noise_types)} ä¸ªæœ‰æ•ˆç»“æœ)")
        logger.info(f"    ğŸ¯ å¹³å‡W-F1: {avg_f1:.2f}% (åŸºäº {len(valid_f1_results)}/{len(noise_types)} ä¸ªæœ‰æ•ˆç»“æœ)")
        
        return {
            'WA (%)': avg_wa,
            'W-F1 (%)': avg_f1,
            'individual_results': noise_results,
            'valid_count': len(valid_wa_results)
        }
    else:
        logger.error(f"âŒ {experiment_name} æ— æœ‰æ•ˆç»“æœ")
        return {
            'WA (%)': 'Error',
            'W-F1 (%)': 'Error',
            'individual_results': noise_results,
            'valid_count': 0
        }

def main():
    """ä¸»å‡½æ•°ï¼Œå®šä¹‰å¹¶è¿è¡Œæ‰€æœ‰EMODBç»†ç²’åº¦æ¶ˆèå®éªŒ"""
    
    # --- å®éªŒé…ç½® ---
    # EMODB ä½¿ç”¨ç¬¬1æŠ˜ (fold=0)ï¼Œæµ‹è¯•å››ç§å™ªå£°ç±»å‹çš„10dBæ¡ä»¶
    TARGET_FOLD = 3  # EMODBé»˜è®¤ä½¿ç”¨ç¬¬1æŠ˜
    BASE_NOISE_PATH = r"C:\Users\admin\Desktop\DATA\processed_features_EMODB_noisy"
    
    # å››ç§å™ªå£°ç±»å‹çš„10dBæ•°æ®è·¯å¾„
    NOISE_TYPES = {
        'babble': f"{BASE_NOISE_PATH}\\root1-babble-10db",
        # 'factory': f"{BASE_NOISE_PATH}\\root1-factory-10db", 
        # 'hfchannel': f"{BASE_NOISE_PATH}\\root1-hfchannel-10db",
        # 'volvo': f"{BASE_NOISE_PATH}\\root1-volvo-10db"
    }

    # å®šä¹‰æ‰€æœ‰æ¶ˆèå®éªŒï¼ˆä¸åŒ…å«å™ªå£°è·¯å¾„ï¼Œè¿è¡Œæ—¶åŠ¨æ€è®¾ç½®ï¼‰
    granular_ablations = [
        # 1. å®Œæ•´æ¨¡å‹ï¼ˆåŸºå‡†ï¼‰
        # {
        #     'name': 'Proposed_Full_Model',
        #     'settings': {
        #         'USE_DACP': True, 
        #         'USE_ECDA': True,
        #         'ANCHOR_CALIBRATION_ENABLED': True,
        #         'USE_ENTROPY_IN_SCORE': True,
        #         'USE_CLASS_AWARE_MMD': True,
        #         'ECDA_CLASS_ATTENTION_LAMBDA': 1.0,
        #         'ECDA_COMPACTNESS_WEIGHT_GAMMA': 0.1,
        #         'ECDA_REPULSION_WEIGHT_DELTA': 0.1
        #     }
        # },
        
        # 2. åŸºçº¿æ¨¡å‹ï¼ˆæ— DACPæ— ECDAï¼‰
        {
            'name': 'Baseline_No_DACP_No_ECDA',
            'settings': {
                'USE_DACP': False, 
                'USE_ECDA': False,
                'FIXED_CONFIDENCE_THRESHOLD': 0.75
            }
        },
        
        # 3. DACPæ¶ˆèï¼šæ— é”šç‚¹æ ¡å‡†
        {
            'name': 'Ablation_DACP_No_Anchor',
            'settings': {
                'USE_DACP': True, 
                'USE_ECDA': True,
                'ANCHOR_CALIBRATION_ENABLED': False
            }
        },
        
        # 4. DACPæ¶ˆèï¼šæ— ç±»åˆ«è‡ªé€‚åº”
        {
            'name': 'Ablation_DACP_No_ClassAdapt',
            'settings': {
                'USE_DACP': True, 
                'USE_ECDA': True,
                'DACP_SENSITIVITY_K': 0.0  # ç¦ç”¨sigmoidæ•æ„Ÿç³»æ•°
            }
        },
        
        # 5. DACPæ¶ˆèï¼šæ— è¯¾ç¨‹å­¦ä¹ 
        {
            'name': 'Ablation_DACP_No_Curriculum',
            'settings': {
                'USE_DACP': True, 
                'USE_ECDA': True,
                'DACP_QUANTILE_START': 0.4,  # è®¾ç½®ä¸ºå›ºå®šå€¼ï¼Œç¦ç”¨åŠ¨æ€å˜åŒ–
                'DACP_QUANTILE_END': 0.4
            }
        },
        
        # 6. DACPæ¶ˆèï¼šä½¿ç”¨ç®€å•ç½®ä¿¡åº¦
        {
            'name': 'Ablation_DACP_Simple_Confidence',
            'settings': {
                'USE_DACP': True, 
                'USE_ECDA': True,
                'USE_ENTROPY_IN_SCORE': False  # ç¦ç”¨ç†µå¢å¼ºçš„ç½®ä¿¡åº¦åˆ†æ•°
            }
        },
        
        # 7. æ— ECDAï¼ˆä»…DACPï¼‰
        {
            'name': 'Ablation_No_ECDA_Only_DACP',
            'settings': {
                'USE_DACP': True, 
                'USE_ECDA': False
            }
        },
        
        # 8. æ— DACPï¼ˆä»…ECDAï¼‰
        {
            'name': 'Ablation_No_DACP_Only_ECDA',
            'settings': {
                'USE_DACP': False,
                'USE_ECDA': True,
                'FIXED_CONFIDENCE_THRESHOLD': 0.75  # ä¸ä½¿ç”¨DACPæ—¶éœ€è¦å›ºå®šé˜ˆå€¼
            }
        },
        
        # 9. ECDAæ¶ˆèï¼šæ›¿æ¢ä¸ºå…¨å±€MMD
        {
            'name': 'Ablation_ECDA_Global_MMD',
            'settings': {
                'USE_DACP': True, 
                'USE_ECDA': True,
                'USE_CLASS_AWARE_MMD': False,  # ä½¿ç”¨å…¨å±€MMD
                'ECDA_COMPACTNESS_WEIGHT_GAMMA': 0.0,  # ç¦ç”¨ç´§å‡‘æ€§æŸå¤±
                'ECDA_REPULSION_WEIGHT_DELTA': 0.0     # ç¦ç”¨æ–¥åŠ›æŸå¤±
            }
        },
        
        # 10. ECDAæ¶ˆèï¼šæ— ç±»åˆ«çº§æ³¨æ„åŠ›
        {
            'name': 'Ablation_ECDA_No_ClassAttention',
            'settings': {
                'USE_DACP': True, 
                'USE_ECDA': True,
                'ECDA_CLASS_ATTENTION_LAMBDA': 0.0  # ç¦ç”¨ç±»åˆ«çº§æ³¨æ„åŠ›
            }
        },
        
        # 11. ECDAæ¶ˆèï¼šæ— ç´§å‡‘æ€§æŸå¤±
        {
            'name': 'Ablation_ECDA_No_Compactness',
            'settings': {
                'USE_DACP': True, 
                'USE_ECDA': True,
                'ECDA_COMPACTNESS_WEIGHT_GAMMA': 0.0  # ç¦ç”¨ç´§å‡‘æ€§æŸå¤±
            }
        },
        
        # 12. ECDAæ¶ˆèï¼šæ— æ–¥åŠ›æŸå¤±
        {
            'name': 'Ablation_ECDA_No_Repulsion',
            'settings': {
                'USE_DACP': True, 
                'USE_ECDA': True,
                'ECDA_REPULSION_WEIGHT_DELTA': 0.0  # ç¦ç”¨æ–¥åŠ›æŸå¤±
            }
        }
    ]
    
    # è¿è¡Œæ‰€æœ‰æ¶ˆèå®éªŒï¼ˆåœ¨å››ç§å™ªå£°ç±»å‹ä¸Šï¼‰
    all_results = {}
    logger.info(f"\n{'='*80}")
    logger.info(f"ğŸš€ å¼€å§‹EMODBç»†ç²’åº¦æ¶ˆèå®éªŒ (Fold {TARGET_FOLD+1}, 10dBå™ªå£°) ğŸš€")
    logger.info(f"ğŸ“Š å°†åœ¨ {len(NOISE_TYPES)} ç§å™ªå£°ç±»å‹ä¸Šæµ‹è¯•: {list(NOISE_TYPES.keys())}")
    logger.info(f"{'='*80}")
    logger.info(f"ğŸ“‹ è®¡åˆ’è¿è¡Œ {len(granular_ablations)} ä¸ªæ¶ˆèå®éªŒ Ã— {len(NOISE_TYPES)} ç§å™ªå£° = {len(granular_ablations) * len(NOISE_TYPES)} ä¸ªè®­ç»ƒä»»åŠ¡")
    logger.info(f"{'='*80}\n")
    
    for i, exp in enumerate(granular_ablations, 1):
        logger.info(f"\n{'='*90}")
        logger.info(f"ğŸ§ª æ¶ˆèå®éªŒ {i}/{len(granular_ablations)}: {exp['name']}")
        logger.info(f"{'='*90}")
        
        try:
            result = run_experiment_on_multiple_noises(
                experiment_name=exp['name'],
                base_settings=exp['settings'], 
                noise_types=NOISE_TYPES,
                fold=TARGET_FOLD
            )
            all_results[exp['name']] = result
            
            if isinstance(result['WA (%)'], (int, float)):
                logger.info(f"âœ… æ¶ˆèå®éªŒ {i} å®Œæˆ - å¹³å‡WA: {result['WA (%)']:.2f}%, å¹³å‡W-F1: {result['W-F1 (%)']:.2f}% (åŸºäº {result['valid_count']}/{len(NOISE_TYPES)} ç§å™ªå£°)")
            else:
                logger.error(f"âŒ æ¶ˆèå®éªŒ {i} å¤±è´¥ - æ— æœ‰æ•ˆç»“æœ")
                
        except Exception as e:
            logger.error(f"âŒ æ¶ˆèå®éªŒ {i} å¤±è´¥: {str(e)}")
            all_results[exp['name']] = {
                'WA (%)': 'Error', 
                'W-F1 (%)': 'Error',
                'individual_results': {},
                'valid_count': 0
            }
    
    # --- æ•´ç†å¹¶ç”Ÿæˆç»“æœè¡¨æ ¼ ---
    logger.info(f"\n{'='*80}")
    logger.info("ğŸ‰ æ‰€æœ‰EMODBç»†ç²’åº¦æ¶ˆèå®éªŒå·²å®Œæˆ! ğŸ‰")
    logger.info(f"{'='*80}\n")

    # åˆ›å»ºåˆ†å±‚ç»“æœè¡¨æ ¼
    table_data = []
    
    # æŒ‰é€»è¾‘é¡ºåºç»„ç»‡ç»“æœï¼ˆç§»é™¤Proposed_Full_Modelï¼Œå› ä¸ºç”¨æˆ·å·²æœ‰æ•°æ®ï¼‰
    experiment_order = [
        ('Ablation_DACP_No_Anchor', 'w/o Anchor Calibration', 0),
        ('Ablation_DACP_No_ClassAdapt', 'w/o Class-Adaptivity', 0),
        ('Ablation_DACP_No_Curriculum', 'w/o Curriculum Progression', 0),
        ('Ablation_DACP_Simple_Confidence', 'w/o Uncertainty Score', 0),
        ('Ablation_No_ECDA_Only_DACP', 'w/o ECDA (Only DACP)', 0),
        ('Ablation_No_DACP_Only_ECDA', 'w/o DACP (Only ECDA)', 0),
        ('Ablation_ECDA_Global_MMD', 'ECDA w/ Global MMD', 0),
        ('Ablation_ECDA_No_ClassAttention', 'ECDA w/o Class Attention', 0),
        ('Ablation_ECDA_No_Compactness', 'ECDA w/o Compactness', 0),
        ('Ablation_ECDA_No_Repulsion', 'ECDA w/o Repulsion', 0),
        ('Baseline_No_DACP_No_ECDA', 'Baseline (No DACP & No ECDA)', 0)
    ]
    
    for exp_key, display_name, level in experiment_order:
        if exp_key in all_results:
            result = all_results[exp_key]
            # æå–å¹³å‡æ€§èƒ½ï¼ˆå¦‚æœæ˜¯æ•°å€¼ï¼‰æˆ–é”™è¯¯ä¿¡æ¯
            wa_avg = result['WA (%)'] if isinstance(result['WA (%)'], (int, float)) else result['WA (%)']
            f1_avg = result['W-F1 (%)'] if isinstance(result['W-F1 (%)'], (int, float)) else result['W-F1 (%)']
            
            table_data.append({
                'Approach': display_name,
                'WA (%)': wa_avg,
                'W-F1 (%)': f1_avg
            })
        else:
            table_data.append({
                'Approach': display_name,
                'WA (%)': 'N/A',
                'W-F1 (%)': 'N/A'
            })
    
    # åˆ›å»ºDataFrameå¹¶è¾“å‡º
    results_df = pd.DataFrame(table_data)
    
    print("\n" + "="*80)
    print("ğŸ“Š EMODBç»†ç²’åº¦æ¶ˆèå®éªŒç»“æœæ±‡æ€»")
    print(f"   ğŸ”Š å››ç§å™ªå£°ç±»å‹10dBå¹³å‡æ€§èƒ½: {list(NOISE_TYPES.keys())}")
    print("="*80)
    print(results_df.to_markdown(index=False, floatfmt=".2f"))
    print("="*80)
    
    # ä¿å­˜ç»“æœåˆ°CSVæ–‡ä»¶
    csv_path = f'emodb_granular_ablation_results_fold_{TARGET_FOLD+1}_10db.csv'
    results_df.to_csv(csv_path, index=False, encoding='utf-8')
    logger.info(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜è‡³: {csv_path}")
    
    # ç”Ÿæˆè¯¦ç»†çš„å™ªå£°ç±»å‹åˆ†è§£è¡¨æ ¼
    print(f"\nğŸ“‹ è¯¦ç»†å™ªå£°ç±»å‹åˆ†è§£è¡¨æ ¼:")
    print("="*100)
    detailed_data = []
    
    for exp_key, display_name, level in experiment_order:
        if exp_key in all_results and 'individual_results' in all_results[exp_key]:
            row_data = {'Approach': display_name}
            individual_results = all_results[exp_key]['individual_results']
            
            # æ·»åŠ å„ç§å™ªå£°ç±»å‹çš„ç»“æœ
            for noise_name in NOISE_TYPES.keys():
                if noise_name in individual_results:
                    wa_val = individual_results[noise_name]['WA (%)']
                    f1_val = individual_results[noise_name]['W-F1 (%)']
                    row_data[f'{noise_name}_WA'] = wa_val if isinstance(wa_val, (int, float)) else 'Error'
                    row_data[f'{noise_name}_F1'] = f1_val if isinstance(f1_val, (int, float)) else 'Error'
                else:
                    row_data[f'{noise_name}_WA'] = 'N/A'
                    row_data[f'{noise_name}_F1'] = 'N/A'
            
            # æ·»åŠ å¹³å‡å€¼
            avg_wa = all_results[exp_key]['WA (%)']
            avg_f1 = all_results[exp_key]['W-F1 (%)']
            row_data['Avg_WA'] = avg_wa if isinstance(avg_wa, (int, float)) else 'Error'
            row_data['Avg_F1'] = avg_f1 if isinstance(avg_f1, (int, float)) else 'Error'
            
            detailed_data.append(row_data)
    
    if detailed_data:
        detailed_df = pd.DataFrame(detailed_data)
        print(detailed_df.to_markdown(index=False, floatfmt=".2f"))
        
        # ä¿å­˜è¯¦ç»†è¡¨æ ¼
        detailed_csv_path = f'emodb_detailed_noise_breakdown_fold_{TARGET_FOLD+1}_10db.csv'
        detailed_df.to_csv(detailed_csv_path, index=False, encoding='utf-8')
        logger.info(f"ğŸ’¾ è¯¦ç»†åˆ†è§£è¡¨æ ¼å·²ä¿å­˜è‡³: {detailed_csv_path}")

    # æ³¨æ„ï¼šå®Œæ•´æ¨¡å‹æ€§èƒ½åˆ†æå·²ç§»é™¤ï¼Œå› ä¸ºç”¨æˆ·å·²æœ‰å®Œæ•´æ¨¡å‹æ•°æ®
    print(f"\nğŸ“ æ³¨æ„: Proposed_Full_Model æœªåŒ…å«åœ¨æ­¤æ¬¡å®éªŒä¸­")
    print(f"         è¯·ä½¿ç”¨æ‚¨ä¹‹å‰çš„å®Œæ•´æ¨¡å‹æ•°æ®ä½œä¸ºåŸºçº¿è¿›è¡Œæ€§èƒ½å¯¹æ¯”åˆ†æ")
    
    print("\n" + "="*80)
    print("âœ… æ¶ˆèå®éªŒåˆ†æå®Œæˆï¼")
    print("ğŸ“Š ä¸»è¦ç»“æœè¡¨æ ¼å’Œè¯¦ç»†åˆ†è§£è¡¨æ ¼éƒ½å·²ç”Ÿæˆï¼Œè¯·å¤åˆ¶åˆ°æ‚¨çš„è®ºæ–‡ä¸­ã€‚")
    print("="*80)

if __name__ == "__main__":
    # ç¡®ä¿è„šæœ¬ä»å…¶æ‰€åœ¨ç›®å½•è¿è¡Œï¼Œä»¥å¤„ç†ç›¸å¯¹è·¯å¾„é—®é¢˜
    os.chdir(os.path.dirname(os.path.abspath(__file__)))
    main()