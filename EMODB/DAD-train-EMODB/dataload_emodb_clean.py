#!/usr/bin/env python3
"""
EmoDBå¹²å‡€æ•°æ®åŠ è½½å™¨
æ”¯æŒè¯´è¯äººéš”ç¦»çš„5æŠ˜äº¤å‰éªŒè¯
10ä¸ªè¯´è¯äººï¼Œæ¯æŠ˜2ä¸ªè¯´è¯äºº
"""

import os
import logging
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split

# å¯¼å…¥åŸºç¡€Datasetç±»
from dataload_clean import CleanEmotionDatasetFromArrays

logger = logging.getLogger(__name__)

# EmoDBè¯´è¯äººIDåˆ—è¡¨ï¼ˆ10æŠ˜äº¤å‰éªŒè¯ï¼Œæ¯ä¸ªè¯´è¯äººç‹¬ç«‹ä¸€æŠ˜ï¼‰
EMODB_SPEAKERS = ['03', '08', '09', '10', '11', '12', '13', '14', '15', '16']

def get_emodb_fold_speakers(fold_id):
    """
    è·å–æŒ‡å®šfoldçš„è®­ç»ƒã€éªŒè¯ã€æµ‹è¯•è¯´è¯äºº
    10æŠ˜äº¤å‰éªŒè¯ï¼š8ä¸ªè¯´è¯äººè®­ç»ƒã€1ä¸ªè¯´è¯äººéªŒè¯ã€1ä¸ªè¯´è¯äººæµ‹è¯•
    
    Args:
        fold_id (int): foldç¼–å· (0-9)
    
    Returns:
        tuple: (train_speakers, val_speaker, test_speaker)
    """
    if fold_id < 0 or fold_id >= 10:
        raise ValueError(f"fold_id must be between 0 and 9, got {fold_id}")
    
    all_speakers = EMODB_SPEAKERS.copy()
    
    # æµ‹è¯•è¯´è¯äººï¼šå½“å‰foldå¯¹åº”çš„è¯´è¯äºº
    test_speaker = all_speakers[fold_id]
    
    # éªŒè¯è¯´è¯äººï¼šä¸‹ä¸€ä¸ªè¯´è¯äººï¼ˆç¯å½¢ï¼‰
    val_speaker = all_speakers[(fold_id + 1) % 10]
    
    # è®­ç»ƒè¯´è¯äººï¼šå…¶ä½™8ä¸ªè¯´è¯äºº
    train_speakers = [spk for spk in all_speakers if spk not in [test_speaker, val_speaker]]
    
    return train_speakers, val_speaker, test_speaker

def load_emodb_clean_data(feature_path, label_dict):
    """
    åŠ è½½EmoDBå¹²å‡€æ•°æ®é›†ï¼ŒåŒ…æ‹¬ç‰¹å¾ã€æ ‡ç­¾å’Œè¯´è¯äººID
    
    Args:
        feature_path: ç‰¹å¾æ–‡ä»¶è·¯å¾„å‰ç¼€ï¼ˆä¸å«æ‰©å±•åï¼‰
        label_dict: æ ‡ç­¾æ˜ å°„å­—å…¸
        
    Returns:
        dict: åŒ…å«ç‰¹å¾ã€æ ‡ç­¾ã€è¯´è¯äººç­‰ä¿¡æ¯çš„æ•°æ®é›†
    """
    logger.info(f"ğŸ“‚ åŠ è½½EmoDBå¹²å‡€æ•°æ®: {feature_path}")
    
    # åŠ è½½ç‰¹å¾
    feats = np.load(f"{feature_path}.npy")
    logger.info(f"   ç‰¹å¾å½¢çŠ¶: {feats.shape}")
    
    # åŠ è½½æ¯ä¸ªæ ·æœ¬çš„é•¿åº¦
    with open(f"{feature_path}.lengths", "r") as f:
        sizes = [int(line.strip()) for line in f]
    logger.info(f"   æ ·æœ¬æ•°é‡: {len(sizes)}")
    
    # åŠ è½½æ ‡ç­¾å¹¶è½¬æ¢ä¸ºæ•°å­—
    with open(f"{feature_path}.lbl", "r", encoding="utf-8") as f:
        labels = [label_dict[line.strip()] for line in f]
    logger.info(f"   æ ‡ç­¾åˆ†å¸ƒ: {np.bincount(labels)}")
    
    # åŠ è½½è¯´è¯äººID
    with open(f"{feature_path}.spk", "r", encoding="utf-8") as f:
        speakers = [line.strip() for line in f]
    
    # ç»Ÿè®¡è¯´è¯äººä¿¡æ¯
    unique_speakers = np.unique(speakers)
    logger.info(f"   è¯´è¯äººæ•°é‡: {len(unique_speakers)}")
    logger.info(f"   è¯´è¯äººID: {unique_speakers}")
    
    # è®¡ç®—åç§»é‡
    offsets = np.concatenate([[0], np.cumsum(sizes)[:-1]])
    
    dataset = {
        "feats": feats,
        "sizes": np.array(sizes),
        "offsets": np.array(offsets),
        "labels": np.array(labels),
        "speakers": np.array(speakers),
        "num": len(labels),
    }
    
    logger.info(f"âœ… EmoDBå¹²å‡€æ•°æ®é›†åŠ è½½å®Œæˆï¼Œå…± {dataset['num']} ä¸ªæ ·æœ¬")
    return dataset

def create_emodb_clean_speaker_isolated_loaders(dataset, fold, batch_size, class_names):
    """
    ä¸ºEmoDBå¹²å‡€æ•°æ®é›†åˆ›å»ºä¸¥æ ¼æŒ‰è¯´è¯äººéš”ç¦»çš„æ•°æ®åŠ è½½å™¨
    10æŠ˜äº¤å‰éªŒè¯ï¼š8ä¸ªè¯´è¯äººè®­ç»ƒã€1ä¸ªè¯´è¯äººéªŒè¯ã€1ä¸ªè¯´è¯äººæµ‹è¯•
    
    Args:
        dataset: æ•°æ®é›†å­—å…¸
        fold: å½“å‰æŠ˜æ•° (0-9)
        batch_size: æ‰¹æ¬¡å¤§å°
        class_names: ç±»åˆ«åç§°åˆ—è¡¨
        
    Returns:
        tuple: (train_loader, val_loader, test_loader)
    """
    if fold < 0 or fold >= 10:
        raise ValueError(f"foldå¿…é¡»åœ¨0-9èŒƒå›´å†…ï¼Œå½“å‰: {fold}")
    
    # è·å–å½“å‰foldçš„è¯´è¯äººåˆ†é…
    train_speakers, val_speaker, test_speaker = get_emodb_fold_speakers(fold)
    
    logger.info("ğŸ“Š EmoDBå¹²å‡€æ•°æ®è¯´è¯äººéš”ç¦»ç­–ç•¥ (10æŠ˜äº¤å‰éªŒè¯):")
    logger.info(f"   å½“å‰æŠ˜: {fold + 1}/10")
    logger.info(f"   ğŸ‹ï¸  è®­ç»ƒè¯´è¯äºº: {train_speakers} (8ä¸ªè¯´è¯äºº)")
    logger.info(f"   ğŸ§ éªŒè¯è¯´è¯äºº: {val_speaker} (1ä¸ªè¯´è¯äºº)")
    logger.info(f"   ğŸ§ª æµ‹è¯•è¯´è¯äºº: {test_speaker} (1ä¸ªè¯´è¯äºº)")
    
    # æ ¹æ®è¯´è¯äººIDè·å–æ ·æœ¬ç´¢å¼•
    # éœ€è¦ä»'emodb_spk_XX'æ ¼å¼ä¸­æå–æ•°å­—éƒ¨åˆ†è¿›è¡ŒåŒ¹é…
    def extract_speaker_id(speaker_full_id):
        """ä»å®Œæ•´è¯´è¯äººIDæå–æ•°å­—éƒ¨åˆ†"""
        return speaker_full_id.split('_')[-1]
    
    # æå–æ•°æ®é›†ä¸­æ‰€æœ‰è¯´è¯äººçš„æ•°å­—ID
    dataset_speaker_ids = np.array([extract_speaker_id(spk) for spk in dataset['speakers']])
    
    train_indices = np.where(np.isin(dataset_speaker_ids, train_speakers))[0]
    val_indices = np.where(dataset_speaker_ids == val_speaker)[0]
    test_indices = np.where(dataset_speaker_ids == test_speaker)[0]
    
    # æ‰“ä¹±è®­ç»ƒé›†
    np.random.shuffle(train_indices)
    
    logger.info(f"   è®­ç»ƒæ ·æœ¬æ•°: {len(train_indices)}")
    logger.info(f"   éªŒè¯æ ·æœ¬æ•°: {len(val_indices)}")
    logger.info(f"   æµ‹è¯•æ ·æœ¬æ•°: {len(test_indices)}")
    
    # éªŒè¯è¯´è¯äººéš”ç¦»
    train_speakers_actual_full = np.unique(dataset['speakers'][train_indices])
    val_speakers_actual_full = np.unique(dataset['speakers'][val_indices])
    test_speakers_actual_full = np.unique(dataset['speakers'][test_indices])
    
    # æå–æ•°å­—IDç”¨äºæ—¥å¿—æ˜¾ç¤º
    train_speakers_actual = [extract_speaker_id(spk) for spk in train_speakers_actual_full]
    val_speakers_actual = [extract_speaker_id(spk) for spk in val_speakers_actual_full]
    test_speakers_actual = [extract_speaker_id(spk) for spk in test_speakers_actual_full]
    
    logger.info(f"   å®é™…è®­ç»ƒè¯´è¯äºº: {train_speakers_actual}")
    logger.info(f"   å®é™…éªŒè¯è¯´è¯äºº: {val_speakers_actual}")
    logger.info(f"   å®é™…æµ‹è¯•è¯´è¯äºº: {test_speakers_actual}")
    
    # ç¡®ä¿æ²¡æœ‰é‡å ï¼ˆä½¿ç”¨æ•°å­—IDè¿›è¡Œæ£€æŸ¥ï¼‰
    assert len(set(train_speakers_actual) & set(val_speakers_actual)) == 0, "è®­ç»ƒé›†å’ŒéªŒè¯é›†è¯´è¯äººé‡å "
    assert len(set(train_speakers_actual) & set(test_speakers_actual)) == 0, "è®­ç»ƒé›†å’Œæµ‹è¯•é›†è¯´è¯äººé‡å "
    assert len(set(val_speakers_actual) & set(test_speakers_actual)) == 0, "éªŒè¯é›†å’Œæµ‹è¯•é›†è¯´è¯äººé‡å "
    
    def create_subset(indices, subset_name):
        """ä»ç´¢å¼•åˆ—è¡¨åˆ›å»ºæ•°æ®é›†å­é›†"""
        if len(indices) == 0:
            raise ValueError(f"æ— æ³•åˆ›å»º{subset_name}ï¼šæ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æ ·æœ¬")
        
        sub_labels = dataset['labels'][indices]
        sub_sizes = dataset['sizes'][indices]
        sub_offsets = dataset['offsets'][indices]
        
        # ç»Ÿè®¡å­é›†æ ‡ç­¾åˆ†å¸ƒ
        label_counts = np.bincount(sub_labels, minlength=len(class_names))
        logger.info(f"   {subset_name}æ ‡ç­¾åˆ†å¸ƒ: {dict(zip(class_names, label_counts))}")
        
        # åˆ›å»ºè¿ç»­çš„ç‰¹å¾æ•°ç»„
        new_feats_list = [dataset['feats'][offset:offset+size] 
                         for offset, size in zip(sub_offsets, sub_sizes)]
        
        if len(new_feats_list) == 0:
            raise ValueError(f"æ— æ³•åˆ›å»º{subset_name}ï¼šç‰¹å¾åˆ—è¡¨ä¸ºç©º")
        
        new_feats = np.concatenate(new_feats_list, axis=0)
        new_sizes = np.array([feat.shape[0] for feat in new_feats_list])
        new_offsets = np.concatenate([np.array([0]), np.cumsum(new_sizes)[:-1]], dtype=np.int64)
        
        return CleanEmotionDatasetFromArrays(
            new_feats, new_sizes, new_offsets, sub_labels
        )
    
    # åˆ›å»ºæ•°æ®é›†
    train_dataset = create_subset(train_indices, "è®­ç»ƒé›†")
    val_dataset = create_subset(val_indices, "éªŒè¯é›†")
    test_dataset = create_subset(test_indices, "æµ‹è¯•é›†")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset, 
        batch_size=batch_size, 
        collate_fn=train_dataset.collator,
        num_workers=0, 
        pin_memory=False, 
        shuffle=True
    )
    
    val_loader = DataLoader(
        val_dataset, 
        batch_size=batch_size, 
        collate_fn=val_dataset.collator,
        num_workers=0, 
        pin_memory=False, 
        shuffle=False
    )
    
    test_loader = DataLoader(
        test_dataset, 
        batch_size=batch_size, 
        collate_fn=test_dataset.collator,
        num_workers=0, 
        pin_memory=False, 
        shuffle=False
    )
    
    return train_loader, val_loader, test_loader

def create_emodb_clean_dataloaders(data_path, batch_size, fold=0):
    """
    åˆ›å»ºEmoDBå¹²å‡€æ•°æ®çš„æ•°æ®åŠ è½½å™¨
    
    Args:
        data_path: æ•°æ®è·¯å¾„
        batch_size: æ‰¹æ¬¡å¤§å°
        fold: å½“å‰æŠ˜æ•° (0-4)
        
    Returns:
        tuple: (train_loader, val_loader, test_loader, num_classes, class_names)
    """
    # EmoDBæ ‡ç­¾æ˜ å°„
    label_dict = {
        'angry': 0,
        'happy': 1,
        'neutral': 2,
        'sad': 3
    }
    
    class_names = ['angry', 'happy', 'neutral', 'sad']
    
    logger.info(f"ğŸ“‚ åˆ›å»ºEmoDBå¹²å‡€æ•°æ®åŠ è½½å™¨ (Fold {fold+1})...")
    
    # åŠ è½½æ•°æ®
    dataset = load_emodb_clean_data(data_path, label_dict)
    
    # åˆ›å»ºè¯´è¯äººéš”ç¦»çš„æ•°æ®åŠ è½½å™¨
    train_loader, val_loader, test_loader = create_emodb_clean_speaker_isolated_loaders(
        dataset, fold, batch_size, class_names
    )
    
    num_classes = len(label_dict)
    
    logger.info(f"âœ… EmoDBå¹²å‡€æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ (Fold {fold+1}):")
    logger.info(f"   è®­ç»ƒæ‰¹æ¬¡æ•°: {len(train_loader)} (æ¥è‡ª {len(train_loader.dataset)} ä¸ªæ ·æœ¬)")
    logger.info(f"   éªŒè¯æ‰¹æ¬¡æ•°: {len(val_loader)} (æ¥è‡ª {len(val_loader.dataset)} ä¸ªæ ·æœ¬)")
    logger.info(f"   æµ‹è¯•æ‰¹æ¬¡æ•°: {len(test_loader)} (æ¥è‡ª {len(test_loader.dataset)} ä¸ªæ ·æœ¬)")
    logger.info(f"   æ‰¹æ¬¡å¤§å°: {batch_size}")
    logger.info(f"   ç±»åˆ«æ•°: {num_classes}")
    
    return train_loader, val_loader, test_loader, num_classes, class_names

if __name__ == "__main__":
    # æµ‹è¯•æ•°æ®åŠ è½½å™¨
    import config_emodb as cfg
    
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO)
    
    # æµ‹è¯•æ•°æ®åŠ è½½
    for fold in range(5):
        print(f"\næµ‹è¯• Fold {fold+1}:")
        train_loader, val_loader, test_loader, num_classes, class_names = create_emodb_clean_dataloaders(
            cfg.CLEAN_FEAT_PATH, cfg.BATCH_SIZE, fold=fold
        )
        
        print(f"Fold {fold+1} - ç±»åˆ«æ•°={num_classes}, ç±»åˆ«å={class_names}")
        
        # æµ‹è¯•ä¸€ä¸ªæ‰¹æ¬¡
        for batch in train_loader:
            print(f"  è®­ç»ƒæ‰¹æ¬¡å½¢çŠ¶: {batch['net_input']['feats'].shape}")
            print(f"  æ ‡ç­¾å½¢çŠ¶: {batch['labels'].shape}")
            break 
        
        for batch in val_loader:
            print(f"  éªŒè¯æ‰¹æ¬¡å½¢çŠ¶: {batch['net_input']['feats'].shape}")
            print(f"  æ ‡ç­¾å½¢çŠ¶: {batch['labels'].shape}")
            break 