import os
import re
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from sklearn.manifold import TSNE
from sklearn.metrics import silhouette_score, calinski_harabasz_score
import matplotlib.pyplot as plt
from collections import Counter
import contextlib
import logging
import json
from datetime import datetime

# ==========================================================================================
# ğŸ”§ 1. é…ç½®åŒºåŸŸï¼šè¯·åœ¨æ­¤å¤„ä¿®æ”¹æƒé‡å’Œæ•°æ®è·¯å¾„
# ==========================================================================================
# é¢„è®­ç»ƒæƒé‡è·¯å¾„ (é€šå¸¸æ˜¯ emotion2vec_base.pt æˆ–æ‚¨åœ¨å¹²å‡€æ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹çš„ .ckpt)
PRETRAINED_WEIGHTS_PATH = r"C:\Users\admin\Desktop\è®ºæ–‡å‚è€ƒ\æœ€ç»ˆçš„ä»£ç å‰¯æœ¬\æœ€ç»ˆä»£ç -æˆªè‡³7.30å·å‰¯æœ¬\ç¬¬ä¸€ç¯‡æœ€ç»ˆçš„ä»£ç \good_-emo\IEMOCAP\pretrain-and-processed-IEMOCAP\train_for_clean_models\best_model_fold_2.ckpt"

# ä¸»å¹²è®­ç»ƒåçš„æƒé‡è·¯å¾„ (åœ¨å™ªå£°æ•°æ®ä¸Šå¾®è°ƒåçš„æ¨¡å‹)
# è„šæœ¬ä¼šè‡ªåŠ¨ä»è¿™ä¸ªè·¯å¾„ä¸­æå–dBä¿¡æ¯æ¥è®¾ç½®å›¾è¡¨æ ‡é¢˜
FINETUNED_WEIGHTS_PATH = r"C:\Users\admin\Desktop\è®ºæ–‡å‚è€ƒ\æœ€ç»ˆçš„ä»£ç å‰¯æœ¬\æœ€ç»ˆä»£ç -æˆªè‡³7.30å·å‰¯æœ¬\ç¬¬ä¸€ç¯‡æœ€ç»ˆçš„ä»£ç \iemocap_mutil-noisy_cross_domain_results\root1\babble\10db\fold_2\models\iemocap_cross_domain_best.pth"

# åŒ…å«å™ªå£°ç‰¹å¾çš„ç›®å½•è·¯å¾„ (åŒ…å« train.npy, train.lengths, train.emo æ–‡ä»¶)
# è¯·ç¡®ä¿è¿™ä¸ªè·¯å¾„æŒ‡å‘æ‚¨æƒ³è¦å¯è§†åŒ–çš„ç‰¹å®šå™ªå£°ç­‰çº§çš„æ•°æ®
NOISY_DATA_ROOT_PATH = r"C:\Users\admin\Desktop\DATA\processed_features_IEMOCAP_noisy\root1-babble-10db"
# ==========================================================================================


# æ—¥å¿—å’Œè®¾å¤‡é…ç½®
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
DEVICE = torch.device('cuda'if torch.cuda.is_available() else 'cpu')
LABEL_DICT = {'ang': 0, 'hap': 1, 'neu': 2, 'sad': 3}
CLASS_NAMES = list(LABEL_DICT.keys())
# å‚è€ƒæ‚¨çš„å›¾ç‰‡ï¼Œä½¿ç”¨ç›¸åŒçš„é¢œè‰²æ˜ å°„ï¼šçº¢ã€ç»¿ã€è“ã€æ©™
EMOTION_COLORS = {
    'ang': '#d62728',    # çº¢è‰² - Anger
    'hap': '#2ca02c',    # ç»¿è‰² - Happiness  
    'neu': '#1f77b4',    # è“è‰² - Neutral
    'sad': '#ff7f0e'     # æ©™è‰² - Sadness
}
EMOTION_LABELS = {
    'ang': 'Anger',
    'hap': 'Happiness', 
    'neu': 'Neutral',
    'sad': 'Sadness'
}


# ==========================================================================================
# æ¨¡å‹å®šä¹‰ (ä» good_-emo/IEMOCAP/DAD-train-IEMOCAP/model.py å¤åˆ¶)
# ä½¿æ­¤è„šæœ¬å¯ä»¥ç‹¬ç«‹è¿è¡Œï¼Œæ— éœ€ä¾èµ–é¡¹ç›®å…¶ä»–æ–‡ä»¶
# ==========================================================================================
class Emotion2VecEncoder(nn.Module):
    def __init__(self, input_dim=768, hidden_dim=256, pretrained_path=None):
        super().__init__()
        self.pre_net = nn.Linear(in_features=input_dim, out_features=hidden_dim)
        self.activate = nn.ReLU()
    def forward(self, x, padding_mask=None):
        x = self.activate(self.pre_net(x))
        if padding_mask is not None:
            x = x * (1 - padding_mask.unsqueeze(-1).float())
            valid_lengths = (1 - padding_mask.float()).sum(dim=1, keepdim=True)
            x = x.sum(dim=1) / torch.clamp(valid_lengths, min=1.0)
        else:
            x = x.mean(dim=1)
        return x

class EmotionClassifier(nn.Module):
    def __init__(self, input_dim: int, num_classes: int, dropout_rate: float = 0.1):
        super().__init__()
        self.dropout = nn.Dropout(dropout_rate)
        self.fc_layer = nn.Linear(in_features=input_dim, out_features=num_classes)
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = self.dropout(x)
        logits = self.fc_layer(x)
        return logits

class SSRLModel(nn.Module):
    def __init__(self, input_dim=768, hidden_dim=256, num_classes=4):
        super().__init__()
        self.student_encoder = Emotion2VecEncoder(input_dim, hidden_dim)
        self.student_classifier = EmotionClassifier(hidden_dim, num_classes)
        # The t-SNE script does not need the teacher network, EMA updates, or loss calculations.
        # We only need the student network structure for loading weights and extracting embeddings.
    
    def get_embeddings(self, x: torch.Tensor, padding_mask=None):
        return self.student_encoder(x, padding_mask)

    def forward(self, x: torch.Tensor, padding_mask=None):
        embedding = self.get_embeddings(x, padding_mask)
        return self.student_classifier(embedding)

# ==========================================================================================
# æ•°æ®åŠ è½½å™¨ (ä¸“ä¸º t-SNE è®¾è®¡ï¼Œå§‹ç»ˆåŠ è½½æ ‡ç­¾)
# ==========================================================================================
def load_emotion2vec_for_tsne(data_path, labels='emo', min_length=1, max_length=None):
    """
    ä¿®æ”¹ç‰ˆåŠ è½½å™¨ï¼šå§‹ç»ˆå°è¯•åŠ è½½æ ‡ç­¾ï¼Œç”¨äºå¯è§†åŒ–ã€‚
    """
    sizes, offsets, emo_labels = [], [], []
    npy_data = np.load(data_path + ".npy")
    offset, skipped = 0, 0
    label_file_path = data_path + f".{labels}"
    
    if not os.path.exists(label_file_path):
        raise FileNotFoundError(f"æ ‡ç­¾æ–‡ä»¶æœªæ‰¾åˆ°: {label_file_path}ã€‚t-SNEéœ€è¦æ ‡ç­¾è¿›è¡Œç€è‰²ã€‚")

    with open(data_path + ".lengths", "r") as len_f, open(label_file_path, "r") as lbl_f:
        for line_idx, (len_line, lbl_line) in enumerate(zip(len_f, lbl_f)):
            length = int(len_line.rstrip())
            # å‡è®¾æ ‡ç­¾åœ¨æ¯è¡Œçš„ç¬¬äºŒåˆ—ï¼Œä¾‹å¦‚ "filename neu" -> "neu"
            lbl_parts = lbl_line.rstrip().split()
            if len(lbl_parts) < 2:
                logger.warning(f"æ ‡ç­¾æ–‡ä»¶ç¬¬ {line_idx+1} è¡Œæ ¼å¼ä¸æ­£ç¡®ï¼Œå·²è·³è¿‡ï¼š'{lbl_line.rstrip()}'")
                offset += length
                skipped += 1
                continue
            lbl = lbl_parts[1]
            
            if length >= min_length and (max_length is None or length <= max_length):
                sizes.append(length)
                offsets.append(offset)
                emo_labels.append(lbl)
            else:
                skipped += 1
            offset += length

    sizes, offsets = np.asarray(sizes), np.asarray(offsets)
    logger.info(f"æˆåŠŸåŠ è½½ {len(offsets)} ä¸ªæ ·æœ¬ç”¨äº t-SNEï¼Œè·³è¿‡äº† {skipped} ä¸ªæ ·æœ¬ã€‚")
    return npy_data, sizes, offsets, emo_labels

class IEMOCAP_tSNE_Dataset(Dataset):
    def __init__(self, data_root_path):
        # å‡è®¾æ•°æ®æ–‡ä»¶åä¸º 'train.npy', 'train.lengths', 'train.emo'
        data_file_path = os.path.join(data_root_path, "train")
        logger.info(f"ä» {data_file_path} åŠ è½½æ•°æ®...")
        
        self.feats, self.sizes, self.offsets, self.labels = load_emotion2vec_for_tsne(data_file_path)
        
        if not self.labels:
            raise ValueError("æœªèƒ½ä»æ•°æ®æ–‡ä»¶ä¸­åŠ è½½ä»»ä½•æ ‡ç­¾ã€‚")
            
        self.numerical_labels = [LABEL_DICT[label] for label in self.labels]
        self.class_counts = Counter(self.labels)
        
        logger.info(f"æ•°æ®é›†åŠ è½½å®Œæˆã€‚å…± {len(self)} ä¸ªæ ·æœ¬ã€‚")
        for label, count in self.class_counts.items():
            logger.info(f"  - ç±»åˆ« '{label}': {count} ä¸ªæ ·æœ¬")

    def __len__(self):
        return len(self.sizes)

    def __getitem__(self, index):
        offset = self.offsets[index]
        size = self.sizes[index]
        end = offset + size
        feats = torch.from_numpy(self.feats[offset:end, :].copy()).float()
        return {"feats": feats, "target": self.numerical_labels[index]}

    def collator(self, samples):
        if len(samples) == 0: return {}
        feats = [s["feats"] for s in samples]
        # ä¿®å¤: æ­¤å‰è¿™é‡Œé”™è¯¯åœ°å†™æˆäº† s['feats'].shape[0]ï¼Œæ˜¯ä¸€ä¸ªå¤åˆ¶/ç²˜è´´é”™è¯¯ã€‚
        # æ­£ç¡®çš„é€»è¾‘æ˜¯ç›´æ¥è·å– feats åˆ—è¡¨ä¸­æ¯ä¸ªå¼ é‡ s çš„å½¢çŠ¶ã€‚
        sizes = [s.shape[0] for s in feats]
        labels = torch.tensor([s["target"] for s in samples], dtype=torch.long)
        
        target_size = max(sizes)
        collated_feats = torch.zeros(len(feats), target_size, feats[0].size(-1))
        padding_mask = torch.ones(len(feats), target_size).bool() # True for padded areas

        for i, (feat, size) in enumerate(zip(feats, sizes)):
            collated_feats[i, :size] = feat
            padding_mask[i, :size] = False # False for valid data
            
        return {
            "net_input": {"x": collated_feats, "padding_mask": padding_mask},
            "labels": labels
        }

# ==========================================================================================
# æ ¸å¿ƒåŠŸèƒ½å‡½æ•°
# ==========================================================================================
def load_model_weights(model, weights_path):
    """åŠ è½½æƒé‡åˆ°æ¨¡å‹"""
    logger.info(f"æ­£åœ¨ä» {weights_path} åŠ è½½æƒé‡...")
    try:
        # ä¿®å¤: å°† weights_only=False ä»¥å…¼å®¹åŒ…å« numpy å¯¹è±¡çš„æƒé‡æ–‡ä»¶
        checkpoint = torch.load(weights_path, map_location=DEVICE, weights_only=False)
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å®Œæ•´çš„è®­ç»ƒæ£€æŸ¥ç‚¹ï¼ˆåŒ…å« model_state_dictï¼‰
        if isinstance(checkpoint, dict) and "model_state_dict" in checkpoint:
            logger.info("æ£€æµ‹åˆ°å®Œæ•´çš„è®­ç»ƒæ£€æŸ¥ç‚¹æ ¼å¼ï¼Œæå– model_state_dict...")
            actual_state_dict = checkpoint["model_state_dict"]
            
            # æ£€æŸ¥æå–çš„ state_dict æ˜¯å¦ç›´æ¥å…¼å®¹
            if "student_encoder.pre_net.weight" in actual_state_dict:
                # æ£€æŸ¥æ˜¯å¦åŒ…å«teacherç½‘ç»œï¼ˆå®Œæ•´SSRLæ¨¡å‹ï¼‰
                if "teacher_encoder.pre_net.weight" in actual_state_dict:
                    logger.info("æ£€æµ‹åˆ°å®Œæ•´çš„SSRLæ¨¡å‹ï¼ˆåŒ…å«teacherå’Œstudentï¼‰ï¼Œåªæå–studentç½‘ç»œæƒé‡...")
                    # åªæå–studentç½‘ç»œçš„æƒé‡
                    student_state_dict = {}
                    for key, value in actual_state_dict.items():
                        if key.startswith('student_'):
                            student_state_dict[key] = value
                    
                    if not student_state_dict:
                        raise RuntimeError("æœªèƒ½ä»å®Œæ•´SSRLæ¨¡å‹ä¸­æå–åˆ°studentç½‘ç»œæƒé‡ã€‚")
                    
                    model.load_state_dict(student_state_dict)
                    logger.info(f"æˆåŠŸä»å®Œæ•´SSRLæ¨¡å‹ä¸­æå–å¹¶åŠ è½½äº† {len(student_state_dict)} ä¸ªstudentç½‘ç»œæƒé‡ã€‚")
                else:
                    # ç›´æ¥å…¼å®¹ SSRL æ¨¡å‹æ ¼å¼
                    model.load_state_dict(actual_state_dict)
                    logger.info("æˆåŠŸåŠ è½½äº†å®Œæ•´çš„SSRLæ¨¡å‹ state_dictã€‚")
            elif "pre_net.weight" in actual_state_dict:
                # éœ€è¦é‡å‘½åæ˜ å°„
                state_dict = model.state_dict()
                loaded_keys = []
                for key, value in actual_state_dict.items():
                    new_key = key
                    if key.startswith('pre_net'):
                        new_key = f"student_encoder.{key}"
                    elif key.startswith('post_net'):
                        new_key = f"student_classifier.{key.replace('post_net', 'fc_layer')}"
                    
                    if new_key in state_dict:
                        state_dict[new_key].copy_(value)
                        loaded_keys.append(new_key)
                    else:
                        logger.warning(f"æƒé‡key '{key}' (æ˜ å°„ä¸º '{new_key}') åœ¨æ¨¡å‹ä¸­ä¸å­˜åœ¨ï¼Œå·²è·³è¿‡ã€‚")
                
                if not loaded_keys:
                    raise RuntimeError("æœªèƒ½ä»æ£€æŸ¥ç‚¹ä¸­åŠ è½½ä»»ä½•æƒé‡ï¼Œè¯·æ£€æŸ¥æƒé‡æ–‡ä»¶å’Œæ¨¡å‹ç»“æ„ã€‚")
                    
                logger.info(f"æˆåŠŸä»æ£€æŸ¥ç‚¹åŠ è½½å¹¶æ˜ å°„äº† {len(loaded_keys)} ä¸ªæƒé‡ã€‚")
            else:
                raise RuntimeError(f"æ£€æŸ¥ç‚¹ä¸­çš„ model_state_dict æ ¼å¼æ— æ³•è¯†åˆ«ã€‚é”®åŒ…æ‹¬: {list(actual_state_dict.keys())[:5]}...")
                
        # å¦‚æœä¸æ˜¯æ£€æŸ¥ç‚¹æ ¼å¼ï¼ŒæŒ‰åŸæ¥çš„é€»è¾‘å¤„ç†        
        elif isinstance(checkpoint, dict) and "student_encoder" in str(list(checkpoint.keys())[0]):
             # å…¼å®¹ä»å®Œæ•´SSRLæ¨¡å‹ä¿å­˜çš„æƒé‡ (e.g., fine-tuned model)
            model.load_state_dict(checkpoint)
            logger.info("æˆåŠŸåŠ è½½äº†å®Œæ•´çš„SSRLæ¨¡å‹ state_dictã€‚")
        # ä¿®å¤ï¼šä¸å†ä¾èµ–æ–‡ä»¶æ‰©å±•åï¼Œè€Œæ˜¯é€šè¿‡æ£€æŸ¥keyæ¥åˆ¤æ–­æ˜¯å¦éœ€è¦é‡å‘½å
        # å¦‚æœæƒé‡keyæ˜¯ 'pre_net.weight' è¿™ç§æ ¼å¼ï¼Œå°±éœ€è¦æ‰‹åŠ¨æ˜ å°„
        elif isinstance(checkpoint, dict) and 'pre_net.weight' in checkpoint:
             # å…¼å®¹æ‚¨çš„ emotion2vec_base.pt æˆ– train_for_clean_models/*.ckpt é¢„è®­ç»ƒæƒé‡æ ¼å¼
            state_dict = model.state_dict()
            # pre_net -> student_encoder.pre_net
            # post_net -> student_classifier.fc_layer
            loaded_keys = []
            for key, value in checkpoint.items():
                new_key = key
                if key.startswith('pre_net'):
                    new_key = f"student_encoder.{key}"
                elif key.startswith('post_net'):
                    new_key = f"student_classifier.{key.replace('post_net', 'fc_layer')}"
                
                if new_key in state_dict:
                    state_dict[new_key].copy_(value)
                    loaded_keys.append(new_key)
                else:
                     logger.warning(f"æƒé‡key '{key}' (æ˜ å°„ä¸º '{new_key}') åœ¨æ¨¡å‹ä¸­ä¸å­˜åœ¨ï¼Œå·²è·³è¿‡ã€‚")
            
            if not loaded_keys:
                raise RuntimeError("æœªèƒ½åŠ è½½ä»»ä½•æƒé‡ï¼Œè¯·æ£€æŸ¥æƒé‡æ–‡ä»¶å’Œæ¨¡å‹ç»“æ„ã€‚")
                
            logger.info(f"æˆåŠŸåŠ è½½å¹¶æ˜ å°„äº† {len(loaded_keys)} ä¸ªé¢„è®­ç»ƒæƒé‡ã€‚")
        else: # å…¼å®¹å…¶ä»–åªåŒ…å« state_dict çš„ .pth æ–‡ä»¶
            model.load_state_dict(checkpoint)
            logger.info("æˆåŠŸåŠ è½½äº† state_dictã€‚")

    except Exception as e:
        logger.error(f"åŠ è½½æƒé‡å¤±è´¥: {e}")
        logger.error("è¯·ç¡®ä¿æƒé‡æ–‡ä»¶ä¸æ¨¡å‹ç»“æ„åŒ¹é…ã€‚")
        import traceback
        traceback.print_exc()
        return False
    return True

@torch.no_grad()
def extract_embeddings(model, dataloader):
    """ä½¿ç”¨æ¨¡å‹ä»æ•°æ®ä¸­æå–æ‰€æœ‰åµŒå…¥å’Œæ ‡ç­¾"""
    model.eval()
    model.to(DEVICE)
    
    all_embeddings = []
    all_labels = []
    
    logger.info("å¼€å§‹æå–ç‰¹å¾åµŒå…¥...")
    for batch in dataloader:
        net_input = batch["net_input"]
        feats = net_input["x"].to(DEVICE)
        padding_mask = net_input["padding_mask"].to(DEVICE)
        labels = batch["labels"]
        
        embeddings = model.get_embeddings(feats, padding_mask)
        
        all_embeddings.append(embeddings.cpu().numpy())
        all_labels.append(labels.cpu().numpy())
        
    logger.info("ç‰¹å¾æå–å®Œæˆã€‚")
    return np.concatenate(all_embeddings, axis=0), np.concatenate(all_labels, axis=0)

def run_tsne(data, n_components=2, perplexity=30, n_iter=1000, random_state=42):
    """è¿è¡Œ t-SNE é™ç»´"""
    logger.info(f"å¼€å§‹è¿è¡Œ t-SNE... (perplexity={perplexity}, n_iter={n_iter})")
    tsne = TSNE(
        n_components=n_components,
        perplexity=perplexity,
        n_iter=n_iter,
        random_state=random_state,
        init='pca',
        learning_rate='auto'
    )
    tsne_results = tsne.fit_transform(data)
    logger.info("t-SNE é™ç»´å®Œæˆã€‚")
    return tsne_results

def plot_tsne_comparison(tsne_results1, tsne_results2, labels, title_info, class_counts):
    """ç»˜åˆ¶ t-SNE å¯¹æ¯”å›¾ï¼Œå‚è€ƒç”¨æˆ·æä¾›çš„é£æ ¼"""
    # è®¾ç½®å›¾ç‰‡å¤§å°å’Œå¸ƒå±€ï¼Œå‚è€ƒç”¨æˆ·çš„é£æ ¼
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 10))
    
    # è·å–å™ªå£°ç­‰çº§ä¿¡æ¯
    db_info = title_info.upper() if title_info != "Unknown DB" else "Unknown"
    
    # è®¾ç½®å·¦å›¾æ ‡é¢˜ - åˆå§‹æƒé‡
    ax1.set_title("(a).Initial Weights Encoder Features - All 5 Sessions", 
                  fontsize=14, fontweight='bold', pad=20)
    
    # è®¾ç½®å³å›¾æ ‡é¢˜ - DADè®­ç»ƒå
    ax2.set_title(f"(b).After DAD Training (10 dB Noise Adapted) Encoder Features - All 5 Sessions", 
                  fontsize=14, fontweight='bold', pad=20)

    # è®¡ç®—ä¸¤ä¸ªæ•°æ®é›†çš„æ€»ä½“åæ ‡èŒƒå›´ï¼Œç¡®ä¿ä¸¤ä¸ªå­å›¾ä½¿ç”¨ç›¸åŒçš„åæ ‡èŒƒå›´
    all_x = np.concatenate([tsne_results1[:, 0], tsne_results2[:, 0]])
    all_y = np.concatenate([tsne_results1[:, 1], tsne_results2[:, 1]])
    
    # æ·»åŠ ä¸€äº›è¾¹è·
    x_margin = (all_x.max() - all_x.min()) * 0.05
    y_margin = (all_y.max() - all_y.min()) * 0.05
    
    x_min, x_max = all_x.min() - x_margin, all_x.max() + x_margin
    y_min, y_max = all_y.min() - y_margin, all_y.max() + y_margin

    # ç»˜åˆ¶æ•£ç‚¹å›¾
    for class_name in CLASS_NAMES:
        class_idx = LABEL_DICT[class_name]
        indices = (labels == class_idx)
        color = EMOTION_COLORS[class_name]
        label = f"{EMOTION_LABELS[class_name]} (n={class_counts[class_name]})"
        
        # å·¦å›¾ï¼šé¢„è®­ç»ƒæ¨¡å‹
        ax1.scatter(tsne_results1[indices, 0], tsne_results1[indices, 1], 
                   c=color, label=label, alpha=0.7, s=20, edgecolors='none')
        
        # å³å›¾ï¼šè®­ç»ƒåæ¨¡å‹
        ax2.scatter(tsne_results2[indices, 0], tsne_results2[indices, 1], 
                   c=color, label=label, alpha=0.7, s=20, edgecolors='none')

    # è®¾ç½®åæ ‡è½´æ ‡ç­¾å’Œå±æ€§
    for ax in [ax1, ax2]:
        ax.set_xlabel('t-SNE Component 1', fontsize=12)
        ax.set_ylabel('t-SNE Component 2', fontsize=12)
        ax.legend(loc="upper right", fontsize=11, frameon=True, fancybox=True, shadow=True)
        ax.grid(True, linestyle='--', alpha=0.3)
        
        # è®¾ç½®ç›¸åŒçš„åæ ‡è½´èŒƒå›´ï¼Œç¡®ä¿ä¸¤ä¸ªå­å›¾å°ºå¯¸ä¸€è‡´
        ax.set_xlim(x_min, x_max)
        ax.set_ylim(y_min, y_max)
        ax.set_aspect('equal', adjustable='box')

    # è°ƒæ•´å¸ƒå±€
    plt.tight_layout()
    
    # ä¿å­˜å›¾åƒ
    save_path = f"IEMOCAP_10dB_DAD_train_tsne.png"
    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
    logger.info(f"t-SNE å¯¹æ¯”å›¾å·²ä¿å­˜è‡³: {save_path}")
    plt.show()
    
    return save_path

def calculate_cluster_metrics(embeddings, labels):
    """è®¡ç®—èšç±»è¯„ä¼°æŒ‡æ ‡"""
    try:
        silhouette = silhouette_score(embeddings, labels)
        calinski = calinski_harabasz_score(embeddings, labels)
        return silhouette, calinski
    except Exception as e:
        logger.warning(f"è®¡ç®—èšç±»æŒ‡æ ‡æ—¶å‡ºé”™: {e}")
        return 0.0, 0.0

def generate_analysis_report(pretrained_embeddings, finetuned_embeddings, labels, class_counts, 
                           title_info, save_path):
    """ç”Ÿæˆè¯¦ç»†çš„åˆ†ææŠ¥å‘ŠJSONæ–‡ä»¶"""
    
    # è®¡ç®—èšç±»æŒ‡æ ‡
    sil_initial, cal_initial = calculate_cluster_metrics(pretrained_embeddings, labels)
    sil_trained, cal_trained = calculate_cluster_metrics(finetuned_embeddings, labels)
    
    # æ„å»ºæŠ¥å‘Šæ•°æ®
    report = {
        "analysis_info": {
            "timestamp": datetime.now().isoformat(),
            "data_source": NOISY_DATA_ROOT_PATH,
            "initial_weights": PRETRAINED_WEIGHTS_PATH,
            "trained_weights": FINETUNED_WEIGHTS_PATH,
            "visualization_method": "t-SNE",
            "noise_level": title_info,
            "output_image": save_path
        },
        "data_statistics": {
            "initial_model_samples": len(labels),
            "trained_model_samples": len(labels),
            "total_samples": len(labels),
            "emotion_classes": [EMOTION_LABELS[name] for name in CLASS_NAMES],
            "class_distribution": {
                EMOTION_LABELS[name]: int(class_counts[name]) for name in CLASS_NAMES
            }
        },
        "cluster_analysis": {
            "initial_weights": {
                "silhouette_score": float(sil_initial),
                "calinski_harabasz_score": float(cal_initial)
            },
            "trained_weights": {
                "silhouette_score": float(sil_trained),
                "calinski_harabasz_score": float(cal_trained)
            },
            "improvement": {
                "silhouette_improvement": float(sil_trained - sil_initial),
                "calinski_improvement": float(cal_trained - cal_initial),
                "silhouette_percentage": float((sil_trained - sil_initial) / abs(sil_initial) * 100) if sil_initial != 0 else 0.0
            }
        },
        "model_analysis": {
            "feature_dimensions": {
                "initial_model": list(pretrained_embeddings.shape),
                "trained_model": list(finetuned_embeddings.shape)
            },
            "tsne_parameters": {
                "n_components": 2,
                "perplexity": 30,
                "n_iter": 1000,
                "random_state": 42
            }
        },
        "interpretation": {
            "purpose": f"Compare encoder feature representations before and after DAD training on {title_info} noise data",
            "data_scope": "All 5 sessions labeled noise data from IEMOCAP dataset", 
            "coverage": "Complete IEMOCAP dataset across all sessions",
            "expected_outcome": "Better class separation and domain adaptation after DAD training",
            "metrics_explanation": {
                "silhouette_score": "Range [-1, 1], higher is better. Measures how well samples are clustered within their own class vs. other classes.",
                "calinski_harabasz_score": "Higher is better. Ratio of between-cluster to within-cluster variance."
            },
            "results_summary": {
                "clustering_improved": bool(sil_trained > sil_initial),
                "separation_improved": bool(cal_trained > cal_initial),
                "overall_assessment": "Improved" if (sil_trained > sil_initial and cal_trained > cal_initial) else "Mixed" if (sil_trained > sil_initial or cal_trained > cal_initial) else "Degraded"
            }
        }
    }
    
    # ä¿å­˜æŠ¥å‘Š
    report_path = f"tsne_analysis_report_{title_info.replace(' ', '_')}.json"
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=4, ensure_ascii=False)
    
    logger.info(f"åˆ†ææŠ¥å‘Šå·²ä¿å­˜è‡³: {report_path}")
    
    # æ‰“å°å…³é”®ç»“æœ
    logger.info("=== èšç±»åˆ†æç»“æœ ===")
    logger.info(f"åˆå§‹æ¨¡å‹ - Silhouette Score: {sil_initial:.4f}, Calinski-Harabasz Score: {cal_initial:.2f}")
    logger.info(f"è®­ç»ƒåæ¨¡å‹ - Silhouette Score: {sil_trained:.4f}, Calinski-Harabasz Score: {cal_trained:.2f}")
    logger.info(f"æ”¹è¿›æƒ…å†µ: Silhouette {sil_trained-sil_initial:+.4f}, Calinski-Harabasz {cal_trained-cal_initial:+.2f}")
    
    return report_path

# ==========================================================================================
# ä¸»æ‰§è¡Œå‡½æ•°
# ==========================================================================================
def main():
    logger.info("====== å¼€å§‹ t-SNE å¯è§†åŒ–è„šæœ¬ ======")
    
    # --- 1. æå–dBä¿¡æ¯ ---
    db_match = re.search(r'(\d+db)', FINETUNED_WEIGHTS_PATH, re.IGNORECASE)
    title_info = db_match.group(1) if db_match else "Unknown DB"
    logger.info(f"ä»è·¯å¾„ä¸­æå–çš„å™ªå£°ç­‰çº§ä¸º: {title_info}")

    # --- 2. åŠ è½½æ•°æ® ---
    try:
        dataset = IEMOCAP_tSNE_Dataset(NOISY_DATA_ROOT_PATH)
        # ä½¿ç”¨è¾ƒå¤§çš„ batch_size ä»¥åŠ å¿«ç‰¹å¾æå–é€Ÿåº¦
        dataloader = DataLoader(dataset, batch_size=128, collate_fn=dataset.collator, shuffle=False)
    except (FileNotFoundError, ValueError) as e:
        logger.error(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
        logger.error("è¯·æ£€æŸ¥ NOISY_DATA_ROOT_PATH æ˜¯å¦æ­£ç¡®ï¼Œå¹¶ç¡®ä¿è¯¥ç›®å½•ä¸‹æœ‰ train.npy, train.lengths, å’Œ train.emo æ–‡ä»¶ã€‚")
        return

    # --- 3. å¤„ç†é¢„è®­ç»ƒæ¨¡å‹ ---
    logger.info("\n--- å¤„ç†é¢„è®­ç»ƒæ¨¡å‹ ---")
    pretrained_model = SSRLModel(input_dim=768, hidden_dim=256, num_classes=len(CLASS_NAMES))
    if not load_model_weights(pretrained_model, PRETRAINED_WEIGHTS_PATH):
        return
    pretrained_embeddings, labels = extract_embeddings(pretrained_model, dataloader)
    
    # --- 4. å¤„ç†ä¸»å¹²è®­ç»ƒåæ¨¡å‹ ---
    logger.info("\n--- å¤„ç†ä¸»å¹²è®­ç»ƒåæ¨¡å‹ ---")
    finetuned_model = SSRLModel(input_dim=768, hidden_dim=256, num_classes=len(CLASS_NAMES))
    if not load_model_weights(finetuned_model, FINETUNED_WEIGHTS_PATH):
        return
    finetuned_embeddings, _ = extract_embeddings(finetuned_model, dataloader)
    
    # --- 5. è¿è¡Œ t-SNE ---
    logger.info("\n--- è¿è¡Œ t-SNE é™ç»´ (å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´) ---")
    tsne_pretrained = run_tsne(pretrained_embeddings)
    tsne_finetuned = run_tsne(finetuned_embeddings)
    
    # --- 6. ç»˜å›¾ ---
    logger.info("\n--- ç»˜åˆ¶å¯¹æ¯”å›¾ ---")
    save_path = plot_tsne_comparison(tsne_pretrained, tsne_finetuned, labels, title_info, dataset.class_counts)
    
    # --- 7. ç”Ÿæˆåˆ†ææŠ¥å‘Š ---
    logger.info("\n--- ç”Ÿæˆåˆ†ææŠ¥å‘Š ---")
    report_path = generate_analysis_report(pretrained_embeddings, finetuned_embeddings, labels, 
                                         dataset.class_counts, title_info, save_path)

    logger.info("\n====== t-SNE å¯è§†åŒ–è„šæœ¬æ‰§è¡Œå®Œæ¯• ======")
    logger.info(f"è¾“å‡ºæ–‡ä»¶:")
    logger.info(f"  - å¯è§†åŒ–å›¾ç‰‡: {save_path}")
    logger.info(f"  - åˆ†ææŠ¥å‘Š: {report_path}")

if __name__ == "__main__":
    main() 